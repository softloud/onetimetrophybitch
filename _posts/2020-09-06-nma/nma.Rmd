---
title: "nma"
description: |
  Work in progress.
author:
  - name: Charles T. Gray
    url: https://github.com/softloud/onetimetrophybitch
date: 09-06-2020
output:
  distill::distill_article:
    self_contained: false
    toc: true
  # html_document:
  #   number_sections: true
  #   toc: true
  #   toc_float: true
  #   code_folding: show
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
 cache = TRUE,
  echo = TRUE)

```


```{r message=FALSE}
# packages used in this blogpost

# general purpose
library(tidyverse) 
library(kableExtra) # tables
library(skimr) # summary
library(patchwork) # vis + vis

# toolchain walkthrough
library(multinma) # network meta-analysis
library(nmathresh) # threshold analysis
library(metafor) # for (non network) meta-analysis

# special purpose
library(fdrtool) # for halfnormal distribution
library(simeta) # borrowing some handy functions 
# note: should port these to my helper functions pkg

# for reproducibility
set.seed(40)

```


# network meta-analysis

Network meta-analysis is a statistical method for aggregating multiple pairwise comparisons on a response of interest. For example, perhaps three studies propose different treatments for a particular medical condition, network meta-analysis enables us to indirectly compare the treatments' effect. Network meta-analysis is a technique for identifying _which_ treatments are more effective than others, rather than _whether_ a treatment is effective [@harrer_doingmetaanalysis_2019]. 

In this toolchain walkthrough [cite], I computationally step through the packages `multinma::` and `nnathresh` for a network meta-analysis with threshold analysis.  

# thinking through the theory

Lots of puzzle pieces. Bayesian network meta-analysis is a form of meta-analysis, and meta-analysis is form of linear regression. We solve for a line of best fit. How do we describe this particular line? 

## linear regression

$$
y \sim \text{normal}(BX, \sigma^2)
$$

## meta-regression

For the $k$th study's effect, for a random effects model, we assume

$$
y_k \sim \text{normal}(\mu + u_k, \sigma_k^2)\\
u_k \sim \text{normal}(0, \tau^2)
$$



## Bayesian network meta-analysis

A network meta-analysis relies on a transitivity assumption whereby indirect comparisons can be constructed from direct comparisons. That is, if we have direct comparisons $\delta_{AC}$ and $\delta_{CB}$, we can construct an indirect comparison of differences [@lumley_networkmetaanalysisindirect_2002].
$$
\delta_{AB} = \delta_{AC} + \delta_{CB}
$$

Since `multinma::` provides tools for Bayesian network meta-analysis, our computational model solves for the posterior, providing the probability of the parameter of interest, $\theta$, given the data, $x$,
$$
P(\theta|x) = \frac{P(x|\theta)P(\theta)}{P(x)}.
$$
And, using the nomeclature of the documentation in `::nma_thresh`, for  random-effects model, we have priors
$$
d \sim \text{normal}(d_0, \Sigma_d)\\
\mu \sim \text{normal}(\mu_0, \Sigma_\mu)\\
$$
and likelihood
$$
y\ |\ d,\mu, \tau^2 \sim \text{normal}(L\delta + M\mu, V)\\
$$
with random effect
$$
\delta \sim \text{normal}(Xd, \tau^2)
$$

Now to explore this theory in action with an example network meta-analysis. 

# example dataset: parkinsons

We'll use an example dataset from `multinma::` with seven studies' results for pairwise comparisons of five treatments of interest for our continuous response measure, 

> the mean off-time reduction in patients given dopamine agonists as adjunct therapy in Parkinson's disease from 7 trials comparing four active drugs and placebo [`?parkinsons` documentation; @phillippo_multilevelnetworkmetaregression_2020; data source @dias2011nice].


```{r}
parkinsons %>% 
  head(3)
```

From `?parkinsons` documentation, we know we have a study variable `studyn`, a treatment variable `trtn`, a measure of effect `y`, and standard error of the effect, `se`, sample size `n`.

First step is to convert the raw data to a network object.

```{r}
# set up the model
arm_net <- set_agd_arm(parkinsons, 
                      study = studyn,
                      trt = trtn,
                      y = y, 
                      se = se,
                      sample_size = n)
arm_net


```

Now we've converted our data to a network object, we can inspect the direct and indirect evidence we have. That is which treatments have a pairwise comparison in at least one study.  

```{r}
plot(arm_net, weight_edges = FALSE)
```

We can see the model will be creating indirect comparisons between treatments such 2 and 3, using the direct evidence in studies that compare 1 and 3, as well as 1 and 2. 

# network meta-analysis

We run the following code to fit a random-effects network meta-analysis model. 

```{r eval=FALSE}
arm_fit_re <- nma(arm_net, 
                  seed = 379394727,
                  trt_effects = "random",
                  prior_intercept = normal(scale = 100),
                  prior_trt = normal(scale = 100),
                  prior_het = half_normal(scale = 5),
                  adapt_delta = 0.99)
```

```{r echo=FALSE}
arm_fit_re <- nma(arm_net, 
                  seed = 379394727,
                  trt_effects = "random",
                  prior_intercept = normal(scale = 100),
                  prior_trt = normal(scale = 100),
                  prior_het = half_normal(scale = 5),
                  adapt_delta = 0.99)
```


We assume a prior distribution on $k = 1, \dots, 5$ treatment effects 
$$
d_k \sim \text{normal}(d_4, 100^2) 
$$
> Is the expected value of $d_k$ now $d_4$ because the default treatment is set to 4 by the model? 

and, similarly, a prior for the study-specific intercepts, $\mu_j$, so that, for $j = 1, \dots, 7$ studies,   
$$
\mu_j \sim \text{normal}(0, 100^2),
$$
and one more prior, on the measure of heterogeneity between studies,
$$
\tau \sim \text{halfnormal}(5^2).
$$
Since we assume a likelihood
$$
y\ |\ d,\mu, \tau^2 \sim \text{normal}(L\delta + M\mu, V)\\
$$
with random effect
$$
\delta \sim \text{normal}(Xd, \tau^2)
$$
our model will give us estimates of $X$, $L$, and $M$. 

In this case, as we are comparing treatments's effects, we are especially interested in $X$, as well as the measure of heterogeneity between the studies, $\tau$. This is reflected in the print output of the nma model.

> I assume this is the standardised mean difference of $d_k$ from treatment effect $d_4$?  

```{r}
arm_fit_re 
```


When we plot the posteriors and with their priors, we see estimates for $M$, the coefficient for study terms, $\mu$, and as well as $X$, the coefficient for treatment effects, and the measure of heterogeneity between studies, $\tau$.  

```{r}
plot_prior_posterior(arm_fit_re)
```

This is measure a mean off-time _reduction_, so I assume a negative value is a bad thing. Then we note that $d_1$ has the largest mean off-time reduction. However, to assess these results more robustly, we turn to a threshold analysis. 

# threshold analysis

`::nma_thresh` for random effects model require 

1. the posterior means `means.dk` of the basic treatment parameters $d_k$, 
2. a likelihood `lhood` covariance matrix,
3. the posterior covariance matrix `post`, posterior covariance mtrix of the vector $(\delta^T, \sigma^T, \mu^T)^T$
4. a design matrix `mu.design` for additional covariates,
5. a design matrix `delta.design` for random effects terms.

```{r posterior means}
post_means <- 
  summary(arm_fit_re, pars=c("d")) %>% 
  as.data.frame() %>%
  pull("mean")

```


```{r mudesign}

# a design matrix for mu.design
M <- matrix(0, nrow = nrow(parkinsons), ncol = 7)

for (i in 1:nrow(parkinsons)) {
  if (parkinsons$trtn[i]) M[i, parkinsons$studyn[i]] <- 1
}


```

```{r likelihood cov}
# for lhood
likelihood_cov <- 
  diag(parkinsons$se^2)

```



```{r}
# for posterior
post_cov <-
  summary(arm_fit_re, pars = c("d")) %>% 
  as.data.frame() %>% 
  pull("sd") %>% 
  as.numeric() %>% 
  map_dbl(.f = function(x){x^2}) %>% 
  diag()


```


```{r}
# construct the design mtrix for eazch contrast
X <- matrix(0, nrow = 15, ncol = 6)

for (i in 1:15){
  X[i, parkinsons$trtn[i]-1] <- 1
  if (parkinsons$studyn[i] != 4){
    X[i, parkinsons$studyn[i]-1] <- -1
  }
}


```


```{r error=TRUE}
thresh <- 
  nma_thresh(
    mean.dk = post_means,
    lhood = likelihood_cov,
    post= post_cov,
    mu.design = M,
    delta.design = X,
    nmatype = "random"
  )


```





# references

