---
title: "nma"
description: |
  Work in progress.
author:
  - name: Charles T. Gray
    url: https://github.com/softloud/onetimetrophybitch
date: 09-06-2020
output:
  distill::distill_article:
    self_contained: false
    toc: true
  # html_document:
  #   number_sections: true
  #   toc: true
  #   toc_float: true
  #   code_folding: show
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
 cache = TRUE,
  echo = TRUE)
```

```{r message=FALSE}
# packages used in this blogpost

# general purpose
library(tidyverse) 
library(kableExtra) # tables
library(skimr) # summary
library(patchwork) # vis + vis

# toolchain walkthrough
library(multinma) # network meta-analysis
library(nmathresh) # threshold analysis

# special purpose
library(fdrtool) # for halfnormal distribution
library(simeta) # borrowing some handy functions 
# note: should port these to my helper functions pkg

# for reproducibility
set.seed(40)

```

# Introduction

Network meta-analysis is a statistical method for aggregating multiple pairwise comparisons on a response of interest. For example, perhaps three studies propose different treatments for a particular medical condition, network meta-analysis enables us to indirectly compare the treatments' effect. Network meta-analysis is a technique for identifying _which_ treatments are more effective than others, rather than _whether_ a treatment is effective [@harrer_doingmetaanalysis_2019]. 

There are several vignettes provided by the package `multinma::` [@phillippo_multilevelnetworkmetaregression_2020], prompting many questions. What different techniques do the vignettes demonstrate? How to perform an nma? And what is the underlying theory?

However, as this is a first deep dive into network meta-analysis, I will restrict myself to the goals:

1. Provide an opinionated toolchain walkthrough of network meta-analysis.
2. Interpret the results using threshold analysis.

# Thinking through the theory

In order to interpret the results produced by the algorithms provided by the packages investigated in this post, I need to ensure I have the conceptual understanding of the computational output. 

Meta-analysis is a ultimately a form of regression, finding a line of best fit through the data. How this equation is solved is not the focus here, but, instead, unpacking the equational structure of a network meta-analysis, starting from linear regression. 

## meta-analysis

A meta-analysis is a special type of linear regression, wherein the response may be thought of as a [linear combination](https://en.wikipedia.org/wiki/Linear_combination) (a construction from set of terms multiplying each term by a constant and adding the results).  

In a simple case of linear regression, we assume the response of interest, $y$, may be thought of in terms of grand mean $\beta_0$ and a covariate $x$ with coeffecicient $\beta_1$, 

$$
y = \beta_0 + \beta_1 x.
$$

and that observations $y_i$ differ slightly from this overall response effect by some sampling error, $\varepsilon \sim N(0, \sigma^2)$, so that, for the $i$th observation, we have  
$$
y_i = B_0 + B_1 x + \varepsilon_i.
$$
Where multiple covariates are to be considered, this construction is generalised to the matrix formula,
$$
\mathbf y = \mathbf {X\beta} + \mathbf{\varepsilon}.
$$
In a random effects model, instead of a coeffecient, a random effect is a term added to the equation that carries its own distribution, similar to the sampling error $\varepsilon$.

A simplest case of a random-effects meta-analysis, without covariates we wish to control the response by, we consider $k = 1, ..., K$ studies' obesrvations in terms of a grand mean across studies, $\mu$ (taking the role of $\beta_0$ above), with a study-specific adjustment, $\theta_k \sim N(0, \tau^2)$, so that the observation for the $k$th study we have
$$
y_k = \mu + \theta_k + \varepsilon_k,
$$
with sampling error $\varepsilon_k \sim N(0, \sigma_k^2)$. 

Note the error, $\varepsilon_k$, for the $k$th study is attributed an associated study-specific variance, $\sigma_k^2$, whereas $\tau^2$, the variance of $\theta_k$ is an aggregate measure of variation across all studies. 

Meta-analysis model can be extended to meta-regression, with the addition of covariates, as with standard linear regression,
$$
y_k = \mu + \theta_k + \mathbf {\beta_k X} + \epsilon_k.
$$

To further complicate matters, a meta-analysis is often a **pairwise comparison** between two groups, a control and and intervention group, with the central question, what is the difference in effect between the two groups across all studies? In this case, the response $y_k$, the aggregated effect $\mu$, and the random effect for variation of this study, $\theta_k$, all measure a pairwise comparison. The pairwise comparison chosen depends on the context of the response variable in question, such as a standardised mean difference (Cohen's $d$), or a bias-adjusted $d$ (Hedge's $g$), for continuous response variables. Similarly, for binary data, an appropriate measure of risk or odds ratios may be chosen [@borenstein_introductionmetaanalysis_2011].   

In the interests of brevity, I'm not labouring the distinction between fixed and random covariates, but I'm sure my understanding could be clearer. This, however, seems a sufficient point from which to further my understanding of network meta-analysis. 

I find this statistical nomenclature confusing. The random effect for the study, $\theta_k$, _is_ a coefficient, as it is indexed by $k$. This is a coefficient for a dummy variable $z_k$ that indicates the study,
$$
z_k = \begin{cases}
1 & \text{if } k = k\\
0 & \text{if } k \neq k
\end{cases}
$$

So, we always have $y$ in terms of linear combination of $z$ and $x$ where we care about one variable $z$, and wish to control for the others $x$.
$$
y_k = \mu + \gamma_k z + \beta_k x + \varepsilon_k
$$



## network meta-analysis

Now, in network meta-analysis we have more than one treatment. The general idea is that we combine pairwise direct comparisons to form an indirect comparison. 

Lumley suggests one way to think of this is with treatments A, B, and C [@lumley_networkmetaanalysisindirect_2002]. We denote $\delta_{XY}$ as the comparison between X and Y, with a positive value of $\delta$ indicating a higher outcome for Y than X, and a negative value of $\delta$ indicates a lower outcome for Y than X. If we have direct comparisons $\delta_{AC}$ and $\delta_{CB}$, we can construct an indirect comparison of differences.
$$
\delta_{AB} = \delta_{AC} + \delta_{CB}
$$
Continuing along with Lumley, we let $i$ and $j$ denote treatments compared by $Y_{ij}$. Since $i$ and $j$ have average true effects $\mu_i$ and $\mu_j$, we have $\delta_{ij} = \mu_i - \mu_j$. Where there was one random effect for the heterogeneity of treatment effect in a standard meta-analysis, there are now two random effects, $\eta_{ik}$ and $\eta_{jk}$ with variance $\tau^2$, for the difference betwteen the average effects of treatments $i$ and $j$ in this study. Another random effect $\zeta_{ij}$ is added to capture 'the inconsistency of this pair of treatments with the rest of the evidence'. The *incoherence* of the network is $\omega = \text{var}(\zeta)$. With these we have the formal model.

\[
\begin{array}{rcl}
Y_{ijk} &\sim& \text{N}(\mu_i - \mu_j + \eta_{ik} + \eta_{jk} + \zeta_{ij}, \sigma^2_{ijk})\\
\eta_{ij} &\sim& N(0, \tau^2)\\
\zeta_{ij} &\sim& N(0, \omega)
\end{array}
\]

# Example: BCG vaccine

The vignette 

```{r eval=FALSE}
# launch vignette in Viewer Pane
vignette("example_bcg_vaccine", "multinma")

```

opens with this unfamiliar command.

```{r}
options(mc.cores = parallel::detectCores())
```
<aside>
My limited understanding is that R was developed for single-core usage. So, I presume this option creates a way some functions can make use of multicore processing. Does this option apply to all functions, or only specific ones that recognise this option has been set?
</aside>

With the library loaded, we can meta-analyse example datasets.

## BCG vaccine for tuberculosis example data

The BCG vaccine for tuberculosis vignette analyses the `bcg_vaccine` dataset provided by `multinma::`.

```{r}
# first few rows of data set 
bcg_vaccine %>% 
    head() %>% 
    kable()

```

From an overview of the data, we see we have 6 columns, 26 rows, 5 numeric variables (columns) and 1 character column, `trtc` which identifies the group as unvaccinated or vaccinated, for a given study.  

```{r}
# get an overview of the data
bcg_vaccine %>% 
    skim()

```

From `bcg_vaccine`'s documentation, we learn that `r` is the number diagnosed with tuberculosis in the follow up period from a sample size of `n`. The latitude of the study is also provided, so comparisons can be made on the basis of the study's relative position within the global south and north.


> The numbers of individuals diagnosed with TB in each arm during the study follow-up period are recorded [@phillippo_multilevelnetworkmetaregression_2020]. 

We can confirm there are two nodes in this network, that is, two interventions of interest, vaccinated and unvaccinated, for each study. 

```{r}
bcg_vaccine %>% 
  count(trtc)

```



## Set up the network

Before modelling as a network meta-analysis, we convert the data to a `nma_data` object with `set_agd_arm`.  

```{r}
bcg_net <- set_agd_arm(
    bcg_vaccine,
    study = "studyn", # which col has study
    trt = trtc, # which col indicates arm
    # these columns are specified bc it is a count outcome
    # i.e., binomial data
    r = r, # col w binomial "success" trials
    n = n, # col w binomial total trials
    trt_ref = "Unvaccinated" # set default level of trt
) 

# what do we get
bcg_net

# what is in this?
stuff_in_net <- bcg_net %>% objects()
stuff_in_net

```

Conventionally, in mathematical statistics, binomially distributed data is described in terms of "successful trials". However, in this case, perhaps it's more informative to think of this as the number of observed tuberculosis cases, out of the patients in a treatment group in a given study. 

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">What&#39;s another word for &quot;success&quot; in binomial trials? <br><br>In this case, it&#39;s number of people who have tuberculosis after treatment. There&#39;s nothing successful about that. <br><br>r = r, # col w binomial &quot;success&quot; trials<br> n = n, # col w binomial total trials</p>&mdash; Charles T. Gray ⚔ (@cantabile) <a href="https://twitter.com/cantabile/status/1301015558863745027?ref_src=twsrc%5Etfw">September 2, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

Most of these objects are empty. The first item is an updated version of the original data, and extractions of the studies and treatments are also provided. Classes, ipd, and contrast do not appear to relevant to this network. 

```{r}

# output everything contained in nma_data class bcg_net object
stuff_in_net %>% 
    map(.f = function(thing){bcg_net %>% pluck(thing)}) %>% 
    set_names(stuff_in_net)

```
<aside>
But what does the network look like? Is there an easy way to plot the underlying graph?

Also, it's interesting from a research software engineering perspective to see how data can be prepared for a modelling function. Model components are extracted, such as `count` for response type, and levels of the treatment variable, in this case, 2 levels. The data are updated with variables that, presumably, the model function recognises. I assume these are the new variables of the form `.*`.
</aside>

## Meta-analysis with no covariates

One question we might ask of the data is given the results of all these studies, what proportion of treated patients still have tuberculosis?

We fit a network meta-analysis model with a fit function. 

```{r}
bcg_nma <- nma(
    bcg_net,
    trt_effects = "random", # specify fixed or random effects model
    prior_intercept = normal(scale = 100),
    prior_trt = normal(scale = 100),
    prior_het = half_normal(scale = 5)
)


```

In order to interpret the results, we describe the model. 

Let $y_k$ denote the pairwise comparison between the unvaccinated and vaccinated groups, for the $k$th study. Then, we assume $y_k$ may be thought of in terms of the overall pairwise comparison, $\mu$, with an adjustment $\theta_k$. To this we add sampling error, $\varepsilon_k$, and, assume $\gamma$ denotes the treatment effect, a component of $\mu$.This provides the following system of assumptions.

\[
\begin{array}{rcl}
y_k & = & \mu + \theta_k + \varepsilon_k\\
\varepsilon_k &\sim& \text{normal}(0, \sigma_k^2)\\
\theta_k &\sim& \text{normal}(0, \tau^2)\\
\tau^2 &\sim& \textrm{halfnormal}(0, 5^2)\\
\mu &\sim& \text{normal}(0, 100^2)\\
\gamma_k &\sim& \text{normal}(0, 100^2)
\end{array}
\]


> What is the standard pairwise comparison for a binomial measure? 

> What is the prior on treatment? How to represent this in terms of model nomenclature?

Now we can use the model nomenclature to interpret the results.

```{r}
# take a look at the raw results
bcg_nma

```

There is a handy function for comparison of the prior and posterior distributions. The prior distributions are displayed as lines, and posterior distributions as histograms. 

```{r priorpost}
plot_prior_posterior(bcg_nma, prior = c("trt", "het"))
```

The straight lines make sense when we see the full density.

```{r prior plots}

# visualisation function that takes a domain and a density with parameters  

prior_plot <- 
  function(y_max, 
           density, 
           pars,
           x_min = -2,
           x_max = 2) {
  
    density_fn <- sprintf("d%s", density) %>% get()
    
  tibble::tibble(
    x = c(x_min, x_max)
  ) %>%
    ggplot(aes(x = x)) +
    stat_function(fun = density_fn, args = pars) +
   ylim(0, y_max) +
      labs(
        title = sprintf(
          "%s(%s)",
          dist_name(density),
          paste0(pars, collapse = ", ")
        ),
        subtitle = sprintf(
          "domain(%s, %s) & codomain(0, %g)",
          x_min,
          x_max,
          y_max
        ),
        y = NULL,
        x = NULL
        )
        
      
}


```

If we plot $N(0, 100^2)$, left, on a wide domain, we see our expected shape of the normal distribution. On the right, we constrain the domain and codomain of the plot by those of the prior posterior plots, we see this is, indeed, same distribution. 

```{r norm plots}

prior_plot(0.005, "norm", list(0, 100), -500, 500) + 
  prior_plot(2, "norm", list(0, 100))

```

The halfnormal distribution, however, does not match the prior/posterior figure generated by `multinma::`, and I'm not sure why.

```{r}

prior_plot(4, "halfnorm", list(5)) +
  prior_plot(2, "halfnorm", list(5))


```

In order to interpret these results



## Comparison with standard random effects model

How do these results compare with a standard random effects model? 

```{r}
# how to rma on binomial count data 

```


## Threshold analysis

In this section, we explore threshold analysis with the `nmathresh::` packkage. 

### Toolchain walkthrough 

The general syntax for a threshold analysis

```{r eval=FALSE}
nma_thresh(mean.dk= d,lhood= V.data, post = V.est, X = X)
```

where `d` is a vector of the estimates for each treatment compared with the control. Likelihood is provided as a covariance matrix for the observed data. 



### General idea

## Meta-regression with latitude covariate

The above analysis leaves out a piece of information, the latitude covariate.

```{r}
bcg_vaccine %>% 
  str()

```

We can regress, updating the random effects model with a coefficient $\beta$ for latitude, by assuming
$$
y_k = \mu + \theta_k + \beta x_{\text{latitude}} + \varepsilon_k. 
$$
where $y_k$ denotes the 

> todo binomial 


# Example: Mean off-time reduction in Parkinson’s disease

```{r eval=FALSE}
vignette("example_parkinsons", "multinma")

```

## Parkisons dataset

```{r}
# take a look at the data
parkinsons %>% head()

parkinsons %>% str()

```

Checking `?parkinsons` documentation, have a study variable `studyn`, a treatment variable `trtn`, a measure of effect `y`, and standard error of the effect, `se`, sample size `n`.

There is also the mean difference of the treatment in the reference arm `diff`, and the standard error of the mean difference `se_diff`. This provides two ways of meta-analysing the data.

> This dataset may be analysed using either an arm-based likelihood using y and se, or a contrast-based likelihood using diff and se_diff (or a combination of the two across different studies) [@phillippo_multilevelnetworkmetaregression_2020].



# References

