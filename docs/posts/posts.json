[
  {
    "path": "posts/2023-03-30-micropackaging/",
    "title": "Explaining research code using reproducibility tools",
    "description": "Simulating meta-analysis data in R with simeta and celebrating a rare moment of avoiding the quagmire of feature creep, the anxiety of past doctoral work, and using data science tools to explain a complex algorithm to a bunch of scientists who have better things to do than go through every line of my code.",
    "author": [
      {
        "name": "Charles T. Gray",
        "url": "https://softloud.github.io/onetimetrophybitch/about.html"
      }
    ],
    "date": "2023-03-30",
    "categories": [
      "simulation",
      "vis",
      "meta-analysis",
      "pipeline",
      "reproducibility",
      "engineering"
    ],
    "contents": "\n\nContents\nsimeta\nwhat this post is about\nthe reproducibility stuff\nreproducibility is not enough\n\nthe struggle is real\nVerbal challenges\nVisual challenges\n\nMicropacking analysis code\n\n\n\n# pkgs used in this post\nlibrary(knitr)\nlibrary(readr)\n\n\nsimeta\nFinally a hex-worthy use of code I wrote for my doctoral project!\n\n\n\nFigure 1: Package site. Thank you, Sarah Romanes, for package name awesomeness, and mange tak, @anatomecha for the sweet hex.\n\n\n\nAnd, by hex-worthy, I mean some other people have use for it. And by some other people, I mean three collaborators, and perhaps some of their collaborators.\nIn my world that is a lot of scientists; a hex-worthy number of scientists!\nwhat this post is about\nUsing simeta for a new project helped me steer past the houses of cards my ever-empretzled doctoral simulation functions had become. Instead of devolving into paralysed state of anxiousness, obsessing about unit tests failing because the test is old not because the code is bad, and knowing I had a very small group of people I need to communicate my results with, I found I was able to shrug off what had held me back from using this code before, and simply get some science done.\nOver my years of writing simulation pipelines, explaining what one point in a visualisation, that is, what the extracted and summarised result of one trial continues to be the challenge I ruminate on.\n\n\n\nFigure 2: New simulation study using simeta functions developed for my doctoral project. Even when drafting a visualisation, I try to hold myself to the rule of finishing the sentence Each point represents… as it helps me keep track of what the visualisation is truly answering.\n\n\n\nThe key lesson I’m taking away from this new version of simeta was in fixing in my mind what my collaborators will use this for. It is technically a software package, but my goal is not to create the greatest software, nor to produce the perfect analysis. It’s to give them interoperable code they can use or rely on for their new analysis.\nIn fact, truth be told, reproducibility also takes a back seat, to documentation. How often do my collaborators really run my code? Instead, collaborators tend to want to fiddle with the parameters and structure of my pipeline, such as sampling distributions or models fit, and I do the dirty work of finding the right line of code to change.\nIn any case, if the simulation study misses the point of their question, which can easily happen when juggling so many parameters, and only having had one preliminary meeting, there’s no point spending all day perfecting the software, tests, and reproducibility.\nThere is no point to demanding workflows of myself and others that will breakdown and we resort to emailing scripts. Instead, I find myself increasingly focussed on using software development and datascience tools to explain the code and explore what might save my collaborators time not just on this project, but in future.\nFor example, explaining the many components of a simulation that are aggregated in a visualisation generated from a make-file, so that my collaborators can incorporate the results of my code into their project.\n\n\n\nFigure 3: It’s useful to combine the simulation and visualisation pipeline. This is the pipeline that produced the simulation results visualised above.\n\n\n\nthe reproducibility stuff\nFirst thing I did was try to make sure my collaborators have a hope of running my code by a doing a bunch of reproducibility stuff, such as:\nArchived esotoric doctoral code and pared down to functions that were useful to my doctoral work and useful to these collaborators (a non-empty intersection, so motivating to think of others using my code)\nRemoved some truly fruity dependencies, and tried to make the package only dependent on standard packages I know my collaborators use, such as tidyverse\nWrote the simulation study make file pipeline shown in Figure 3, visualised in Figure 2 my first try at understanding their problem\nTidied up the function documentation and created a quick summary in the readme of the simulation\nreproducibility is not enough\nReproducibility is all well and good, I’m quite pleased with my progress there. To be honest, there’s plenty more to do. Instead of debugging the existing tests, which were extensive, just for starters.\nReproducibility and good enough computational science can be a sinkhole of time, and what bothers me is that even if I tick all those boxes, I don’t feel as if the package is ready to be shipped.\nthe struggle is real\n\nHorse Come On GIFfrom Horse GIFs\n\nI have fallen prey to the sinkhole of despair, caught in a quagmire between good enough data science practice, inevitable feature creep, and documentation becoming such a daunting task. It is ever a challenge to clearly communicate what one trial in one simulation is to my collaborators, and how this was computationally achieved.\nIndeed, I intended this post to be a picture-book visual walkthrough of the simulation pipeline, to show you, dear reader. The readme has my current attempt, but it is no where near the picture-book walkthrough I’m aiming for.\nWith the goal of pushing before Copenhagen’s PyData this evening, I’m leaving the picture book for another day. Here are some of the challenges that prevented me from finding an optimal path to fully explaining my package.\nVerbal challenges\nI try to to complete the phrase Each point represents… in each simulation visualisation I create, but it is easy for it the sentence become a combinatorially complicated, overburdened mash of for a given, for each, and with respect to clauses.\nVisual challenges\nSimulation parameters easily get out of hand. There are only so many levels that look for colour, less for shape. There are also only so many categorical variables that can be encoded total.\nMicropacking analysis code\nAlthough my picturebook walkthrough isn’t perfected, I know I’ve made a better effort to document what is in the simulation pipeline than I have for any previous analysis.\nIt once again strikes me how it’s easy to narrowly interpret the benefits of reproducibility with respect to scientific trustworthiness. However noble that may be, I tend to find my appreciation for the tools of reproducibility are more in terms of improving accessibility and interoperabiltiy of collaborative computational science.\nFor example, by packaging the functions, it was easy to generate examples of the subprocesses of the simulation pipeline in the readme. And the function is automatically generated by pkgdown. My collaborators can then understand easier what toolchain outputs I’m inspecting with them, look at the documentation, and they can open an issue if there is something they don’t understand. The documentation can always updated and improved.\nIt’s been a good lesson in learning to release and use open source code, getting it to good enough reproducibility and accessibility without losing months to pointless computational busywork, particularly appeasing persnickety software development gods. I think a real pitfall for me is finding tools associated with reproducibility very useful for disseminating research code; however, analyses rarely need to be at CRAN levels of robustness, and it’s easy to fall into sinkholes of computationally inferior despair.\nWhat matters is doing my best, within a realistic time frame, to help my collaborators understand and rely on my work. Science is always incremental, including code; I improved this codebase because it’s needed for a new project. If it’s needed again, I’ll improve it some more.\n\n\n\n",
    "preview": "posts/2023-03-30-micropackaging/logo.png",
    "last_modified": "2023-03-30T14:39:23+02:00",
    "input_file": "micropackaging.knit.md"
  },
  {
    "path": "posts/2023-01-19-spotify/",
    "title": "Spotify API miniboss",
    "description": "Limping through authentication just far enough to analyse number of tracks on the soundtrack to my life playlists over the last couple of years",
    "author": [
      {
        "name": "Charles T. Gray",
        "url": "https://softloud.github.io/onetimetrophybitch/about.html"
      }
    ],
    "date": "2023-01-19",
    "categories": [
      "spotify",
      "vis",
      "engineering"
    ],
    "contents": "\n\nContents\nlistening habits\ngetting the data\nauthentication\n\nanalysing my playlist\ncategories\nquestions that don’t\nneed answers\nfinding title variable\nplaylist titles\nengineering playlist\ndata\nvisualising playlist\ndata\nengineering track data\n\n\n\n\n# packages used in this blogpost\nlibrary(tidyverse) # all-purpose datasci metapkg\nlibrary(gt) # pretty tables\nlibrary(spotifyr) # for accessing my spotify data\nlibrary(skimr)\n\n\nIt occurs1 to me that I now have a dataset of\nplaylists in Spotify , and this dataset is, for a data scientist,\nastonishingly corrupted. If I cannot access anything else\ndata-wise, I can do a string analysis of the names of my playlists and\ncould blogpost on how many mistakes I made with them alone.\nlistening habits\nFor twenty years, my primary income was music. I’ve variously\nsubstituted this income with roles in scientific programming over the\nlast decade, transitioning into a fulltime career when I completed my\ndoctorate a year ago. My outlet for the music that used to dominate my\nlife, especially moving countries without a piano, are my Spotify\nplaylists.\nMusic is a constant soundtrack to my life; I’m a High Fidelity grrl\nliving a future-noir musical in my head, dancing on the metro around\nCopenhagen like no one can see.\nI have two soundtrack to my life playlists for different purposes at\nall times, but regularly create new soundtracks to life, at the moment\nit is every season.\n\n\n# set up playlist dataset\ncategories <-\n    tibble(\n        in_this_post = c('lw', 'mct'),\n        playlist = c(\n            \"lifes::work\",\n            \"maybe i'll code today\"\n        ),\n        purpose = c(\n            \"scientific programming, inspired\",\n            \"scientific programming when feeling unproductive or sad and travelling about Copenhagen on the magic carpet transport system\"\n        )\n    )\n\ngt(categories)\n\n\nin_this_post\n      playlist\n      purpose\n    lw\nlifes::work\nscientific programming, inspiredmct\nmaybe i'll code today\nscientific programming when feeling unproductive or sad and travelling about Copenhagen on the magic carpet transport system\n\n\nHow do I get text to wrap in a code chunk? And, for that matter, .Rmd?\ngetting the data\nI shall begin this analysis as I begin every new type of analysis, by\nasking the internet how to do it.\nFirst few hits mentioned a CRAN package spotifyr, which sounds\npromising, indeed.\n\n\n# > (in console)\ninstall.packages('spotifyr')\n\n\nauthentication\nMoments like these I always deeply appreciate the open source\ncommunity for understanding how little skill I have for dealing with\nAPIs; my entire education was equations on a blackboard.\n\nSet up a Dev account with Spotify\n\nFind Client ID and Client Secret\n> spotifyr::get_spotify_access_token()\nRequest failed [400]. Retrying in 1 seconds...\nRequest failed [400]. Retrying in 3.1 seconds...\nError in spotifyr::get_spotify_access_token() : \n>\nWhat did I misunderstand about the instructions? I searched the site,\nbut this yielded lots of documentation but still no answer. So I tried\ncreating an app, and sure enough, yup, there’s the\nClient ID.\n\nFind Client ID and Client Secret\n\nSet authentication to system environment\n\n\n# >\nSys.setenv(SPOTIFY_CLIENT_ID = 'xxxxxxxxxxxxxxxxxxxxx')\nSys.setenv(SPOTIFY_CLIENT_SECRET = 'xxxxxxxxxxxxxxxxxxxxx')\n\n\nI’ve made this mistake before; I find it confusing that I need to\ncreate something called an application just to give myself\nauthentication to access data.\nNow to try it; browse the package reference. get_my_playlists\nis exactly where I want to start.\n\n\n# >\nget_my_playlists()\n\n\nWhich redirected me to a site displaying the following text. This is\ndisheartening.\n\nINVALID_CLIENT: Invalid redirect URI\n\nDid I restart R after updating the System Environment?\n> library(spotifyr)\n> get_my_playlists()\nWaiting for authentication in browser...\n\nThis time the browser page displayed new text.\n\nMissing required parameter: client_id\n\nCuriouser and curiouser. Are system environments case sensitive?\nFirst, to check that I have actually stored my system variables.\n\n\n# > \nSys.getenv()\n\n\nCan’t see them. Will inspect file.\n\n\n# > \nlibrary(usethis)\nedit_r_environ() # this took me to local\n\n\nTime to try those console commands again.\n\n\n# >\nSys.setenv(SPOTIFY_CLIENT_ID = 'xxxxxxxxxxxxxxxxxxxxx')\nSys.setenv(SPOTIFY_CLIENT_SECRET = 'xxxxxxxxxxxxxxxxxxxxx')\nSys.getenv()\n\n\nAnd, magically, they are there now. Hopefully does it. Restarting R\nagain.\n\n\n# > \nlibrary(spotifyr)\nget_my_playlists()\n\n\nOh ffs.\n\nMissing required parameter: client_id\n\n\n\n# > \nSys.getenv(\"SPOTIFY_CLIENT_ID\")\n\n\n\n[1] \"\"\n\nI think I’ll just edit my .Renviron myself. Trying again.\n\n\n# > \nlibrary(spotifyr)\nget_my_playlists()\n\n\nAha! I needed to see the image in this\npost to understand I needed to add a local host to my Spotify dev\napp’s settings.\nOnce again, learning the lesson that some things cannot be solved\nwith R.\nanalysing my playlist\ncategories\nNow that I can access my Spotify data, let’s see what I have to work\nwith.\nI have been creating lw and mct playlists for years now. For a while\nI was sometimes creating a playlist by the month. Currently I have been\ncreating playlists by the season.\n\nWhy am I labelling maybe i’ll code today mtc in playlist\ntitles? It’s not even an intitialism.\nquestions that don’t need\nanswers\nI know I have divided playlists into instrumental and indie, broadly,\nand attempted to tag these playlists by lw and mct categories and when I\ninstantiated the playlist.\nWhat are my listening habits over time?\nWhat artists appear the most in my playlists?\nWhat are my favourite tracks?\nTo further define these questions, I need to find out what variables\nI have access to. I am assuming I can access my playlist titles, and the\ntracks in them.\nfinding title variable\n\n\n# writing file locally so I don't have to fiddle with auth\nlibrary(spotifyr)\nsp_playlists_raw <- get_my_playlists(limit = 50)\n\nwrite_csv(sp_playlists_raw, 'data/spotdat.csv')\n\n\n\n\nsp_playlists_raw <- read_csv('../../data/spotdat.csv')\n\n# what variables we have\n\nskim(sp_playlists_raw)\n\nTable 1: Data summary\nName\nsp_playlists_raw\nNumber of rows\n47\nNumber of columns\n20\n_______________________\n\nColumn type frequency:\n\ncharacter\n14\nlogical\n5\nnumeric\n1\n________________________\n\nGroup variables\nNone\nVariable type: character\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\nhref\n0\n1\n59\n59\n0\n47\n0\nid\n0\n1\n22\n22\n0\n47\n0\nname\n0\n1\n3\n33\n0\n47\n0\nsnapshot_id\n0\n1\n56\n60\n0\n47\n0\ntype\n0\n1\n8\n8\n0\n1\n0\nuri\n0\n1\n39\n39\n0\n47\n0\nexternal_urls.spotify\n0\n1\n56\n56\n0\n47\n0\nowner.display_name\n0\n1\n7\n9\n0\n3\n0\nowner.href\n0\n1\n42\n58\n0\n3\n0\nowner.id\n0\n1\n9\n25\n0\n3\n0\nowner.type\n0\n1\n4\n4\n0\n1\n0\nowner.uri\n0\n1\n22\n38\n0\n3\n0\nowner.external_urls.spotify\n0\n1\n39\n55\n0\n3\n0\ntracks.href\n0\n1\n66\n66\n0\n47\n0\nVariable type: logical\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\ncollaborative\n0\n1\n0.11\nFAL: 42, TRU: 5\ndescription\n47\n0\nNaN\n:\nimages\n47\n0\nNaN\n:\nprimary_color\n47\n0\nNaN\n:\npublic\n0\n1\n0.72\nTRU: 34, FAL: 13\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\ntracks.total\n0\n1\n37.17\n63.53\n0\n10.5\n15\n27\n323\n▇▁▁▁▁\n\nThere are a number of link variables, and it will take some\nexperimentation to figure out which to use, but that is for formatting\ninto the labels. There are two variables that will be useful for\nanalysis. Happily, I have 47 total playlists on Spotify, and Spotify’s\nAPI allows for a Maximum of 50.\nInspecting this, as well as running the dataset through a quick\n::View, I see there are two useful variables.\n\n\nplaylist_var <- sp_playlists_raw %>% \n    select(\n        playlist = name,\n        n_tracks = tracks.total\n    )\n\nplaylist_var %>% head() %>% gt()\n\n\nplaylist\n      n_tracks\n    mtc winter 2022\n10l::w winter 2022\n11julehygge 2022\n10Life is a musical\n16l::w fall-2022\n12pentatonicisation\n8\n\nplaylist titles\nI’m interested in the playlists with mtc which should be\nmct, so will need to search for both, and then there’s\nlw which is written as l::w. I’ve always been\nwell aware I’d probably end up doing an analysis on these data at some\npoint, yet I was unable to fix this. Let’s take a look at the\ndamage.\n\n\n# all playlist titles\nplaylist_var %>% pull(playlist)\n\n [1] \"mtc winter 2022\"                  \n [2] \"l::w winter 2022\"                 \n [3] \"julehygge 2022\"                   \n [4] \"Life is a musical\"                \n [5] \"l::w fall-2022\"                   \n [6] \"pentatonicisation\"                \n [7] \"mtc-fall 2022\"                    \n [8] \"mtc summer-2022\"                  \n [9] \"l::w summer-2022\"                 \n[10] \"Super fun happy time\"             \n[11] \"Old timey\"                        \n[12] \"Blues like no one’s watching\"     \n[13] \"Eurovison faves\"                  \n[14] \"2022-spring maybe i’ll code today\"\n[15] \"Danish Indie Gems\"                \n[16] \"2022-spring l::w\"                 \n[17] \"Blues dancing\"                    \n[18] \"70s sugar pop\"                    \n[19] \"2022-02 lifeswork\"                \n[20] \"2022-02 maybe i'll code today\"    \n[21] \"2022-01 l::w\"                     \n[22] \"2021-12 l::w\"                     \n[23] \"2021-12 maybe i'll code today\"    \n[24] \"2021-11 maybe i'll code today\"    \n[25] \"folk\"                             \n[26] \"2021-11 mct\"                      \n[27] \"2021-09 maybe I’ll code today\"    \n[28] \"2021-08 maybe I’ll code today\"    \n[29] \"2021-07 lifeswork\"                \n[30] \"2021-07 maybe i'll code today\"    \n[31] \"2021 June\"                        \n[32] \"2021 may\"                         \n[33] \"Film\"                             \n[34] \"Indie\"                            \n[35] \"electro swing\"                    \n[36] \"writing\"                          \n[37] \"dishbrush ballads\"                \n[38] \"Punk\"                             \n[39] \"karaoke\"                          \n[40] \"trip hop\"                         \n[41] \"hip hoppity\"                      \n[42] \"old timey\"                        \n[43] \"romantic\"                         \n[44] \"bop\"                              \n[45] \"baroque\"                          \n[46] \"yoga triphop\"                     \n[47] \"yoga film\"                        \n\nI’ll start by describing a category variable to filter the\ndataset.\n\n\nplaylist_counts <- \n    playlist_var %>% \n    mutate(\n        category = case_when(\n                    str_detect(playlist, 'mtc') ~ 'mct',\n                    str_detect(playlist, 'mct') ~ 'mct',\n                    str_detect(playlist, 'code') ~ 'mct',\n                    str_detect(playlist, 'l::w') ~ 'lw',\n                    str_detect(playlist, 'lifeswork') ~ 'lw'\n                )) %>% \n                filter(\n                    !is.na(category)\n                ) %>% group_by(category)\n\n\ngt(playlist_counts)\n\n\nplaylist\n      n_tracks\n    mct\n    mtc winter 2022\n10mtc-fall 2022\n17mtc summer-2022\n262022-spring maybe i’ll code today\n142022-02 maybe i'll code today\n292021-12 maybe i'll code today\n92021-11 maybe i'll code today\n102021-11 mct\n02021-09 maybe I’ll code today\n132021-08 maybe I’ll code today\n192021-07 maybe i'll code today\n6lw\n    l::w winter 2022\n11l::w fall-2022\n12l::w summer-2022\n242022-spring l::w\n122022-02 lifeswork\n22022-01 l::w\n92021-12 l::w\n152021-07 lifeswork\n11\n\nNot sure if I have any playlists labelled with lw, but\nI’ll inspect the antijoin to see if I missed anything.\n\n\nanti_join(playlist_var, playlist_counts) %>% pull(playlist)\n\n [1] \"julehygge 2022\"               \"Life is a musical\"           \n [3] \"pentatonicisation\"            \"Super fun happy time\"        \n [5] \"Old timey\"                    \"Blues like no one’s watching\"\n [7] \"Eurovison faves\"              \"Danish Indie Gems\"           \n [9] \"Blues dancing\"                \"70s sugar pop\"               \n[11] \"folk\"                         \"2021 June\"                   \n[13] \"2021 may\"                     \"Film\"                        \n[15] \"Indie\"                        \"electro swing\"               \n[17] \"writing\"                      \"dishbrush ballads\"           \n[19] \"Punk\"                         \"karaoke\"                     \n[21] \"trip hop\"                     \"hip hoppity\"                 \n[23] \"old timey\"                    \"romantic\"                    \n[25] \"bop\"                          \"baroque\"                     \n[27] \"yoga triphop\"                 \"yoga film\"                   \n\nYay, looks good.\nengineering playlist data\n\n\nplaylist_dat <-\n    playlist_counts %>% \n        # extract variables from playlist titles\n        mutate(year = str_extract(playlist, '\\\\d{4}') %>% as.integer(),\n               month = str_extract(playlist, '-\\\\d{2}\\\\s') %>% \n                   str_remove('-') %>% \n                   str_remove('\\\\s') %>% \n                   as.integer(),\n               season = case_when(\n                   str_detect(playlist, 'winter') ~ 'winter',\n                   str_detect(playlist, 'summer') ~ 'summer',\n                   str_detect(playlist, 'fall') ~ 'fall',\n                   str_detect(playlist, 'autumn') ~ 'fall',\n                   str_detect(playlist, 'spring') ~ 'spring'\n               ),\n               # assign seasons for month-labelled playlists, using BOM \n               season = case_when(\n                  is.na(month) ~ season,\n                  month == 12 | month <= 2 ~ 'winter',\n                  month <= 5 ~ 'spring',\n                  month <= 8 ~ 'summer',\n                  month <= 11 ~ 'fall'\n               ) %>% \n                   fct_relevel('spring', 'summer', 'fall', 'winter'),\n               # interesting, I just realised I've lived three countries over these datasets\n               country = case_when(\n                   # no straya :( \n                   month <= 3 & year <= 2021 ~ 'straya',\n                   year == 2021 ~ 'uk',\n                   year == 2022 & month < 4 ~ 'uk',\n                   TRUE ~ 'danmark'\n               ) %>% fct_relevel('uk')\n               \n                   ) %>% \n        # remove empty playlist \n        filter(n_tracks > 0) %>% \n        # arrange categories chronologically\n        ungroup() %>%\n        mutate(\n            season_year = if_else(\n                month <= 2 & season == 'winter',\n                as.integer(year - 1),\n                year\n            ),\n            season_year = if_else(is.na(season_year), year, season_year)\n            \n        ) %>% \n        arrange(category, season_year, season, month) %>% \n        select(-month) \n\n# a random sample of rows\n\nsample_n(playlist_dat, 5)\n\n# A tibble: 5 × 7\n  playlist          n_tracks category  year season country season_year\n  <chr>                <dbl> <chr>    <int> <fct>  <fct>         <int>\n1 2022-02 lifeswork        2 lw        2022 winter uk             2021\n2 mtc summer-2022         26 mct       2022 summer danmark        2022\n3 2021-12 maybe i'…        9 mct       2021 winter uk             2021\n4 2021-09 maybe I’…       13 mct       2021 fall   uk             2021\n5 2021-11 maybe i'…       10 mct       2021 fall   uk             2021\n\n\nSee now, this is what I’m talking about. Look at these variable names.\nThe sheer variety of ways I’ve input playlist names, even though I knew\nI’d want to do this analysis at some point. I can see now seasons are\nnot sufficient, I need to adopt a data input of season-month.\nAlright, I think I’ve got all the variables I can engineer for the\nplaylist dataset.\nvisualising playlist data\nI still want to get the track data, but let’s take a look what I\nhave.\n\n\nseason_dat <- \nplaylist_dat %>%\n    group_by(category, season_year, season) %>% \n    select(playlist, n_tracks, season, season_year) %>% \n    ungroup() %>% \n    mutate(\n        season = fct_relevel(season, 'spring', 'summer'),\n        timepoint = str_c(season_year, '-', season)\n    ) %>% \n    arrange(category, season_year, season) %>%\n    ungroup() \n\n\n\n\n# perhaps storing as an object will help reduce file size\nseason_plot <- \nseason_dat %>% \n    rename(year = season_year) %>%\n    left_join(\n        tibble(\n            category = c('mct', 'lw'),\n            genre = c('indie', 'film music')\n        )\n    ) %>% \n    ggplot(aes(x = season, \n               weight = n_tracks, \n               fill = playlist)\n           ) +\n    geom_bar(show.legend = FALSE) +\n    facet_grid(genre ~ year, scales = 'free') +\n    theme_minimal(base_size = 15) +\n    scale_fill_grey() +\n    theme(panel.grid.major.x = element_blank()\n    ) +\n    labs(\n        title = \"Number of tracks on the soundtrack to my life over time\" %>% str_wrap(35),\n        subtitle = \"Colour indicates playlist\",\n        x = \"\",\n        y = \"\",\n        caption = \"Ah, so many stories, even in this first analysis of two playlists I create for programming and everything else at semi-regular intervals; I live every day filled with an anthemic soundtrack for my everyday tasks of coding and travelling around Copenhagen's magic carpet transport system. There's the dip in 2021 when I was never hitting flow hard enough to turn to my focus playlist. Meanwhile, I probably listened to those 20ish indie tracks intensely, one or two to obsessive levels. Winter in the UK a year ago was lonely and I listened to a lot of music for comfort. Summer was a good time in Copenhagen for me, got lots of work done, and put time into curating a good programming playlist. Fall was hard. Winter, of course, is only halfway through, so is necessarily smaller, but my productivity is lifting and playlist growing. \" %>% str_wrap(60)\n    ) \n\n\n\n\nseason_plot\n\n\n\nengineering track data\n\nHa, for a follow-up blog post, I guess.\n\nLost half the day to authentication.\nAlso this:\n\nformat link variables; figure out href variables\n\nNothing like unemployment to inspire\na blog post; I was one of eight people recently laid off at a\nneuroscience consultancy in Copenhagen. Life just got spicy.↩︎\n",
    "preview": "posts/2023-01-19-spotify/spotify_files/figure-html5/unnamed-chunk-19-1.png",
    "last_modified": "2023-03-30T10:26:09+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-07-09-ikigai/",
    "title": "Discipline matters more than effort",
    "description": "Data visualisations that jostle in my mind hearing the usual early career advice",
    "author": [
      {
        "name": "Dr. Charles T. Gray",
        "url": "https://softloud.github.io/onetimetrophybitch/about.html"
      }
    ],
    "date": "2022-07-09",
    "categories": [],
    "contents": "\n\nContents\nwhat was true\nthen, ain’t necessarily so, now\nyears\nbetween opportunities in some disciplines\nprecarious\nacademic employment is still a privilege\ni’m a pragmatist\nikigai\n\nAdvice to early career researchers is variously given along the lines\nof: publish as much as possible; contribute to the discipline’s\ncommunity; participate in the department with teaching and seminars.\nAlso consider internships, consulting, writing blogposts, and\ncommunicating research to the public.\nWhat is often skimmed over, if addressed at all, is the\nextraordinarily wide disparity of opportunity between disciplines\nagainst a backdrop of worsening working conditions for everyone.\nHaving graduated with a thesis in film musicology first, and then a\nPhD in mathematical science, I have been through both experiences\nillustrated in the following visualisation.\n\n\nShow code\n\n# get parameters for plot\n# devtools::install_github(\"softloud/parameterpal\")\nlibrary(parameterpal)\n\ndiscipline_a <- beta_pal(0.6, 0.3, 0.8)\ndiscipline_b <- beta_pal(0.2, 0.1, 0.8)\n\n\n\n\nShow code\n\n# plot function\nset.seed(42)\nlibrary(tidyverse)\nlibrary(viridis)\n\nobs <- 100\n\n\n\nsimdat <- \n    tibble(\n        x = rbeta(obs, discipline_a[[1]], discipline_a[[2]]),\n        discipline = \"A\"\n    ) %>%   \n    bind_rows(\n        tibble(\n            x = rbeta(obs, discipline_b[[1]], discipline_b[[2]]),\n            discipline = \"B\"\n        ) \n    ) \n\nquants <-    \n    simdat %>% \n    group_by(discipline) %>% \n    summarise(\n        first = quantile(x, 0.25),\n        second = quantile(x, 0.5),\n        third = quantile(x, 0.75)\n    )\n\n\ndisc_plot <- \n    function(simdat, quants) {\n\n\n\nplotdat <- \n    simdat %>% \n    left_join(quants) %>% \n    mutate(\n        effort = case_when(\n            x > third ~ \"Publishes, teaches, seminars, blog, & service\" %>% \n                str_wrap(25),\n            x > second ~ \"Publishes & teaches\",\n            x > first ~ \"Publishes\",\n            TRUE ~ \"Graduates\"\n        )\n    )\n\n\n\n\nplotdat  %>%\n    rename(Effort = effort) %>% \n    ggplot(aes(x = discipline, y = x)) +\n    geom_boxplot(\n        alpha = 0.4\n    ) +\n    geom_jitter(aes(colour = Effort), alpha = 0.7) +\n    labs(\n       \n        x = \"Made up disciplines (these are randomly generated data)\" %>% \n            str_wrap(30),\n        y = \"Totally made up probability of obtaining a domain position\" %>% \n            str_wrap(30)\n        \n    ) +\n    ylim(0, 1) +\n    theme_minimal(\n        base_size = 18,\n        base_family = \"serif\"\n    ) +\n    theme(\n        legend.direction = \"horizontal\",\n        legend.position = \"top\",\n        axis.text.y = element_blank(),\n        panel.grid = element_blank()\n    ) +\n    scale_color_viridis(\n        direction = -1,\n        discrete = TRUE,\n        guide =\n    guide_legend(\n        ncol = 2\n    )\n    )         \n    }\n\n\n\n\nShow code\n\ndisc_plot(simdat, quants) +\n    labs(\n         title = \"Discipline matters more than effort\",\n        subtitle = \"Opportunities vary more between domains of interest than in terms of effort\" %>% \n            str_wrap(45),\n        caption = \"Think of each point as a person; an aspiring scholar with a passion. No matter how hard a scholar in Discipline B optimises within discipline, according to various advice provided by mentors (e.g., teach, publish, contribute to community), that scholar will at best achieve the opportunities available to the lowest quartile of Discipline A.\" %>% \n            str_wrap(80)\n    )\n\n\n\nwhat was true then,\nain’t necessarily so, now\nI was told a lot of things that did not hold true: a high distinction\nguarantees PhD scholarship; recruiters would contact so much it would be\nannoying; an undergraduate degree from a reputable university should\nprovide the foundation of a comfortable middle-class life. I think,\nhowever, these things were true for the people who said these\nthings.\nWhy have things changed? So many reasons. For example, in Australia,\nuniversities are financially incentivised to produce postgraduates,\neffectively regardless of career outcomes. The result is a lot more\npostgraduates; “Ah, the PhD bubble”, commented a professor to me in the\ntea room one day.\nIf I assume the things I’ve been told were true, then there was not\nonly higher likelihood of obtaining a position, but also less of a\npenalty between disciplines, when the person providing this advice\nformed their opinions.\n\n\nShow code\n\n# adjustment for opportunity \ntime_a <- beta_pal(0.6 + 0.1, 0.2, 0.6)\ntime_b <- beta_pal(0.2 + 0.5, 0.1, 0.8)\n\n# randomly generate some data\ntimedat <- \n    tibble(\n        x = rbeta(obs, time_a[[1]], time_a[[2]]),\n        discipline = \"A\",\n        timepoint = \"Some decades ago\"\n    ) %>%   \n    bind_rows(\n        tibble(\n            x = rbeta(obs, time_b[[1]], time_b[[2]]),\n            discipline = \"B\",\n        timepoint = \"Some decades ago\"\n        ) \n    ) \n\ntime_quants <-\n        timedat %>% \n    group_by(discipline) %>% \n    summarise(\n        first = quantile(x, 0.25),\n        second = quantile(x, 0.5),\n        third = quantile(x, 0.75)\n    )\n\n\n# combine with original dataset\n\ntime_obs <-\n    simdat %>% \n    mutate(\n        timepoint = \"Now\" \n    ) %>% \n    bind_rows(timedat) %>% \n    mutate(\n        timepoint = fct_relevel(timepoint, \"Some decades ago\")\n        \n    )\n    \n\ntime_quants <-\n    time_obs %>% \n     group_by(discipline, timepoint) %>% \n    summarise(\n        first = quantile(x, 0.25),\n        second = quantile(x, 0.5),\n        third = quantile(x, 0.75)\n    )\n\n\n\n\nShow code\n\n    disc_plot(time_obs, time_quants) +\n    facet_wrap(~ timepoint) +\n    labs(\n        title = \"There are more PhD graduates now\",\n        subtitle = \"Opportunity was greater for some fields, some decades ago, and opportunity was more balanced between disciplines\" %>% \n            str_wrap(55)\n    )\n\n\n\nyears between\nopportunities in some disciplines\nA friend found, on graduating from a PhD in literature, that there\nsimply were no postdoctoral positions in the field. Similiarly, when I\nasked the one public service department that had been known to hire\nalgebraists when there would be postdoctoral positions, they could not\nsay. For some disciplines, there are far more graduates than there are\npositions, and only some of the top outliers get through.\n\n\nShow code\n\n# set parameters for discipline with almost no opportunity\ndiscipline_c <- beta_pal(0.05, 0.2, 0.8)\n\ndisc_c_obs <-\ntibble(\n        x = rbeta(obs, discipline_c[[1]], discipline_c[[2]]),\n        discipline = \"C\"\n    ) %>% \n    bind_rows(simdat)\n\ndisc_c_quants <- \n    disc_c_obs %>% \n    group_by(discipline) %>% \n summarise(\n        first = quantile(x, 0.25),\n        second = quantile(x, 0.5),\n        third = quantile(x, 0.75)\n    )\n\n\n\n\nShow code\n\ndisc_plot(disc_c_obs, disc_c_quants) +\n    labs(\n        title = \"No matter how hard you try\",\n        subtitle = \"In some disciplines, there is almost no chance of obtaining a domain position\" %>% \n            str_wrap(45)\n    )\n\n\n\nIn addition, administrative procedures often cause delays, even when\ngrants have been approved and everyone is in agreement. It is\nexceedingly difficult to weather these economic troughs without family\nmembers to fall back on. Harder still, creeping self doubt.\nprecarious\nacademic employment is still a privilege\nUntil my current position, academia had best working\nconditions I have ever experienced. My postdoctoral position,\nlast year, was the first time in my life I had a wage.\nI turned 42 recently. First time in my life I have had\npaid sick leave. First time I didn’t have to\nwork every weekend. The sessional work I did in\nacademia, prior to finishing my studies, was better than casual work I\ncould obtain otherwise. And casual work, dear reader, was all I could\nget.\nThe opportunities to mingle with fascinating people with fascinating\nstories about science were unparalleled. Travel was such a gift; I’d\nnever much been able to afford to leave the country, or stay in hotels.\nAll in all, I loved my time in academia. I sought a position in\nconsulting because I need greater stability than academia can afford to\nmanage complex post-traumatic stress disorder.\nI am not saying that working conditions for early career researchers\nare good. I tend to gesture at the slow demise of neoliberalism, how it\nis causing tectonic shifts in working conditions that are stratifying\nsociety into two classes: those who are serviced; and those who provide\nservices. Another might point to the pandemic, or other drivers. Point\nis what used to be comfortable occupations have shifted into the\nprecariat class. Eroding working conditions for academics are in a\ncontext of eroding working conditions for most occupations.\ni’m a pragmatist\nI’m certainly not the cleverest mathematician, nor a programmer with\na deep understanding of technique. I find research anxiety inducing. I\nneed to be pragmatic about where my energy levels are at for effort, and\nconsider where this will place me in the quartiles of my chosen\ndiscipline. Suppose my effort is in the middle; I certainly don’t feel\nI’ve optimised being an early career researcher.\nI didn’t choose to what I’m good at, nor what I loved. I switched\nfrom pure mathematics to statistics to data science as I formed the\nperception of opportunity illustrated in the visualisations in this\npost. I knew I could not weather being without income. I am also tired\nand do not wish to reinvent myself again anytime soon. I had to ensure\nmy postgraduate studies would lead to employment using the domain I was\ntrained in.\n\n\nShow code\n\n# suppose i am in the second quartile of effort\nme <- \nsimdat %>% \n    left_join(quants) %>% \n    filter(\n        x > (first + 0.05), \n            x < (second - 0.05), \n            discipline == \"A\") %>% \n    sample_n(1) %>% \n    select(x, discipline) %>% \n    mutate(label = \"Me\")\n\n\n\n\nShow code\n\ndisc_plot(simdat, quants) +\n    geom_text(\n        data = me,\n        aes(label = label),\n        size = 5,\n        family = \"serif\"\n    ) + \n    labs(\n        title = \"I'm no outlier\",\n        subtitle = \"Suppose I'm somewhere in the middle when it comes to effort\" %>% str_wrap(45)\n    )\n\n\n\nikigai\nAlthough this post might sound like one of necessary gloom; for me,\nthere is little gloom because I optimised along these paths. I didn’t\nset out to work in data science, I began with an interest in\nmathematics. It is in data science, however, I’ve been able to indulge\nso many other unexpected interests; I use my writing skills more than I\nexpected, for example. I don’t think my job description will stay fixed;\nam approaching with curiosity about where my postgraduate studies will\ntake me next.\nThe lesson, for me, was to embrace not defining myself as any one\nthing, and not to focus on what I think I’m good at. I am not a\nmathematician, nor a programmer, nor a piano teacher. Today I aspire to\nbe a mathematical scientist, but who knows what I’ll aspire to be\ntomorrow.\nMaybe I’ll never know what I’m good at, but I hope I continue to\nsurprise myself.\n\n\n\n",
    "preview": "posts/2022-07-09-ikigai/ikigai_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-03-30T10:26:09+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-29-lists/",
    "title": "list and unlist",
    "description": "In which I continue to be confused about ::unlist, but manage to join two lists, as required",
    "author": [
      {
        "name": "Charles T. Gray",
        "url": "https://softloud.github.io/onetimetrophybitch/about.html"
      }
    ],
    "date": "2021-03-29",
    "categories": [
      "codeflow"
    ],
    "contents": "\n\n\n# pkgs used\nlibrary(tidyverse)\n\n\n\n\n\nfirst_list <-\n  list(\n    a = letters[1:3],\n    b = \"mittens\",\n    c = c(TRUE, FALSE),\n    d = rnorm(4)\n  )\n\nsecond_list <- \n  list(\n    e = \"buttons\",\n    f = letters[1:5],\n    g = runif(2)\n  )\n  \n\n# if I have a list(list, list) how do I get list of the elmenets of hte list? \n# Elements of first list as elements,\n# and elements of second list as elements?\n\nunlist(first_list, second_list) %>% \n  dim()\n\n\nNULL\n\n# huh dim?\n\nunlist(first_list, second_list) %>% \n  class()\n\n\n[1] \"character\"\n\n# character?!\n\nunlist(first_list, second_list)\n\n\n                  a1                   a2                   a3 \n                 \"a\"                  \"b\"                  \"c\" \n                   b                   c1                   c2 \n           \"mittens\"               \"TRUE\"              \"FALSE\" \n                  d1                   d2                   d3 \n\"-0.658853976666822\"  \"-1.29571869155379\" \"-0.541580614619811\" \n                  d4 \n\"-0.150846740435645\" \n\n# oh it made everything flat, that's not what I want. I still want the elements \n# to remain lists, what about this recursive argument?\n\nunlist(first_list, second_list, recursive = FALSE) \n\n\n                  a1                   a2                   a3 \n                 \"a\"                  \"b\"                  \"c\" \n                   b                   c1                   c2 \n           \"mittens\"               \"TRUE\"              \"FALSE\" \n                  d1                   d2                   d3 \n\"-0.658853976666822\"  \"-1.29571869155379\" \"-0.541580614619811\" \n                  d4 \n\"-0.150846740435645\" \n\n# okay, maybe I'm overthinking this, what happens if I make a list of two lists\nlist(first_list, second_list)\n\n\n[[1]]\n[[1]]$a\n[1] \"a\" \"b\" \"c\"\n\n[[1]]$b\n[1] \"mittens\"\n\n[[1]]$c\n[1]  TRUE FALSE\n\n[[1]]$d\n[1] -0.6588540 -1.2957187 -0.5415806 -0.1508467\n\n\n[[2]]\n[[2]]$e\n[1] \"buttons\"\n\n[[2]]$f\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\n[[2]]$g\n[1] 0.08550033 0.32802539\n\n# ugh, no I think I ended up with a list of 2 lists\nlist(first_list, second_list) %>% \n  str()\n\n\nList of 2\n $ :List of 4\n  ..$ a: chr [1:3] \"a\" \"b\" \"c\"\n  ..$ b: chr \"mittens\"\n  ..$ c: logi [1:2] TRUE FALSE\n  ..$ d: num [1:4] -0.659 -1.296 -0.542 -0.151\n $ :List of 3\n  ..$ e: chr \"buttons\"\n  ..$ f: chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n  ..$ g: num [1:2] 0.0855 0.328\n\n# see I have a list of 4 and a list of 3, I want a list of 7, not a list of 2 \n# comprising 4 and 3 ugh\n\n# can I use map to extract the elements?\nmap(first_list, 1)\n\n\n$a\n[1] \"a\"\n\n$b\n[1] \"mittens\"\n\n$c\n[1] TRUE\n\n$d\n[1] -0.658854\n\n# how is this different from first list?\nfirst_list\n\n\n$a\n[1] \"a\" \"b\" \"c\"\n\n$b\n[1] \"mittens\"\n\n$c\n[1]  TRUE FALSE\n\n$d\n[1] -0.6588540 -1.2957187 -0.5415806 -0.1508467\n\n# oh that's not what I want\n# fuck me, I'm going to look this up on the tubes now.\n\n\n\nAnd switch to a post. This is proving to be more involved than I thought.\nThis post on stackoverflow suggests using ::append, despite the function saying it is for vectors. Worth a try.\n\n\nappend(first_list, second_list)\n\n\n$a\n[1] \"a\" \"b\" \"c\"\n\n$b\n[1] \"mittens\"\n\n$c\n[1]  TRUE FALSE\n\n$d\n[1] -0.6588540 -1.2957187 -0.5415806 -0.1508467\n\n$e\n[1] \"buttons\"\n\n$f\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\n$g\n[1] 0.08550033 0.32802539\n\n# compare with \nfirst_list\n\n\n$a\n[1] \"a\" \"b\" \"c\"\n\n$b\n[1] \"mittens\"\n\n$c\n[1]  TRUE FALSE\n\n$d\n[1] -0.6588540 -1.2957187 -0.5415806 -0.1508467\n\nsecond_list\n\n\n$e\n[1] \"buttons\"\n\n$f\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\n$g\n[1] 0.08550033 0.32802539\n\nHuh, well, there you go. So a base function to the rescue.\n\n\n\n",
    "preview": {},
    "last_modified": "2023-03-30T10:26:09+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-10-24-incorrigible-tidyvert/",
    "title": "incorrigible tidy::vert",
    "description": "a song with %>% references",
    "author": [
      {
        "name": "Charles T. Gray",
        "url": "https://twitter.com/cantabile"
      }
    ],
    "date": "2019-10-24",
    "categories": [
      "music"
    ],
    "contents": "\n\nContents\nincorrigible tidy::vert %>%  exegesis()\nthe %>% operator in the R language\nWhat is an operator?\nWhat is a composite?\n\nWhy do I love to %>%?\nincorrigible tidy::vert %>%  lyrics()\niphone balanced on music stand quality recording\n\nincorrigible tidy::vert %>%  exegesis()\n\nThis post was adapted for inclusion in a joint publication of mathematically-informed artworks engaging with Magritte’s pipe, an icon of surrealism. This manuscript is from a working group of researchers who met at the 2019 Heidelberg Laureate Forum.\n\n\nThank you, Laura Ación, Hao Ye, and James Goldie for checking the maths, and for the reflections on %>%.\n\nIn his 1929 surrealist painting, The Treachery of Images, René Magritte declares Ceci n’est pas une pipe (This is not a pipe). In so doing, he highlights this is but an image, a representation, of a pipe, not truly a pipe itself.\n\nThe Treachery of Images, René Magritte, 1929. Image source: wikipedia.\nI recently wrote a song with lots of references to R and the tidyverse:: metapackage(Wickham 2017).\nI didn't mean to %>% your bubble\nI'm just an incorrigible tidy::vert\nIn this post, I’ll unpack the pipe operator, %>%, that features throughout the lyrics.\nthe %>% operator in the R language\n\n\n\nFigure 1: Image source: magritrr:: GitHub repository.\n\n\n\nThe %>% pipe operator is the first major concept introduced in the programming section, following exploratory data analysis and data wrangling, of Wickham’s R for Data Science (Grolemund and Wickham 2017).\nWith Stefan Milton Bache’s magrittr::(Bache and Wickham 2014) package,\n\n\n# f(x) is equivalent to x %>% f() with magrittr::\n\nlibrary(magrittr)\n\n# f(x)\nround(3.1)\n\n\n[1] 3\n\n# is equivalent to x %>% f()\n\n3.1 %>% round()\n\n\n[1] 3\n\nWhat is an operator?\nWe often forget that operators are, themselves, functions.\nBrian A. Davey’s MAT4GA General Algebra coursebook (what I have on hand) provides this definition.\nFor \\(n \\in \\mathbb N_0 := \\mathbb N \\cup \\{ 0\\}\\), a map \\(f : A^n \\to A\\) is called an n-ary operation on A.\nFor example, \\(+\\) is a function that takes two arguments, numbers, and returns a single number. Algebraically, 3 + 2 = 5 is shorthand for +(3, 2) = 5.\nFor those with formal mathematical training, multiple uses of the %>% operator in a single line of code can be thought of in terms of a coding instantiation of a composite of functions.\nWhat is a composite?\nLet \\(f\\) and \\(g\\) be real functions.\nThe composite of \\(f\\) with \\(g\\) is the real function \\(g \\circ f\\) given by the formula \\((g \\circ f)(x) := g(f(x))\\).\nFor reasons that only made sense to me once I reached graduate-level mathematics, we read a composite of functions from right to left.\nAnd just to break our brains a little, algebraically, the composite operator is a function, so we have \\(g \\circ f = \\circ (f, g)\\)!\nThe pipe, %>%, operator is the R-language equivalent to the composite \\(\\circ\\) operator on real functions.\nWhy do I love to %>%?\nHere is an example with three functions: \\((h \\circ g \\circ f)(x) := h(g(f(x))).\\)\n\n\nset.seed(39)\n\n# get a random sample size between 20 & 100\nsample(seq(20, 100), 1) %>% # this f(x) goes into\n  # generate sample from normal distribution with \n  # mean 50 & sd 0.5\nrnorm(., 50, 0.5) %>% # g, so, now g(f(x), which goes into\n  # calculate mean of that sample\n  mean() # h, so h(g(f(x)))\n\n\n[1] 49.94228\n\nTo see how this is the \\((h \\circ g \\circ f)(x)\\) instantiation, reading from right to left, we take a look at the \\(h(g(f(x)))\\) instantiation of the same code.\n\n\n# this line of code is equivalent to above\n# h(g(f(x))) is less text\n# but the algorithm is harder to ascertain \nmean(rnorm(sample(seq(20, 100), 1), 50, 0.5))\n\n\n[1] 49.98828\n\nThe reader is invited to consider if they agree with the author that it is harder to read the symbols so close together, in this \\(h(g(f(x)))\\) instantiation of the code. Also, arguably more importantly, one does not have the ability to comment each component of the algorithm.\nThere is a downside to the %>%, however. The longer a composite becomes, the more difficult it is to identify errors.\n \nOn the the train Leipzig with snow falling\nAnd my %>%s are getting too long\n\nincorrigible tidy::vert %>%  lyrics()\n\n\n\nCaught the train to Leipzig, snow is falling\nBut I am not nearly done\nRube Goldberging this algorithm\nBut the sampling is off.\n\nI didn't mean to %>% your bubble\nI'm just an incorrible tidy::vert\n\nAnd I'm here to tell ya\nThere's some rhyme and reason\nBut there's a whole lot that can get fucked up\n\nAnd I'm here to tell ya\nThere's scarce rhyme and reason\nSo let's brace for the shitstorm\n\nDon't think I'll unravel\nThe mysteries of the beta distribution\nOn the the train Leipzig with snow falling\nAnd my %>%s are getting too long\n\nBut I didn't mean to %>% your bubble\nI'm just an incorrible tidy::vert\n\nAnd I'm here to tell ya\nThere's some rhyme and reason\nBut there's a whole lot that can get fucked up\n\nAnd I'm here to tell ya\nThere's scarce rhyme and reason\nSo let's brace for the CRANstorm\n\nAnd I didn't mean to %>% your bubble\nLet your flame war flame itself out\nAnd I didn't mean to %>% your bubble\nExcuse Me, Do You Have a Moment \n to Talk About Version Control?\n\nAnd I didn't mean to %>% your bubble\nI'm just an incorrible tidy::vert\nAnd I didn't mean to %>% your bubble\nI'm just an incorrible tidy::vert\n\n\niphone balanced on music stand quality recording\nDon’t say I didn’t warn you about the sound quality.\n\n\n\n\n\nBache, Stefan Milton, and Hadley Wickham. 2014. “Magrittr: A Forward-Pipe Operator for R.”\n\n\nGrolemund, Garrett, and Hadley Wickham. 2017. R for Data Science.\n\n\nWickham, Hadley. 2017. “Tidyverse: Easily Install and Load the ’Tidyverse’.”\n\n\n\n\n",
    "preview": "posts/2019-10-24-incorrigible-tidyvert/pipe-logo.png",
    "last_modified": "2023-03-30T10:26:09+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-28-quack-quack-said-the-duck/",
    "title": "quack! quack! said the duck",
    "description": "making sense of methods in R",
    "author": [
      {
        "name": "cantabile",
        "url": {}
      }
    ],
    "date": "2019-03-28",
    "categories": [
      "dev"
    ],
    "contents": "\n\nContents\nafter a cursory look at UseMethod documentation\nmake a duck quack, with a little help from Josiah\nstuff I still don’t get\nmeritget\na duck for maelle\n\n\nSome time back, @malco_barrett and I discovered we both had tidyverse::-integrated functions in development for meta-analysis models, specifically models produced by metafor::rma.\nWe started to discuss how to bring together the work we’d done, and then, speaking for myself, I got busy and overwhelmed last year with the general craziness that doing a doctorate is, and this slipped way back on the backburner.\nLast week, however, one of the creators of the broom:: package got in touch with Malcolm about porting the code. And, with the Evidence Synthesis Hackathon imminent, it seems as if the time is nigh. If I’m going to be able to collaborate on this, that means finally getting around to learning about methods in R.\n\n\nCracks metaphoric R knuckles.So, S3. What's that all about?\n\n— Charles T. Gray (@cantabile) March 27, 2019\n\nI think I might find this pedagogically interesting in future, to reflect on where I started today, and where I ended up.\n\n\nJourney begins here: my current impression is that, digging back 8 years ago to my one compsci subject, first year java, S3 is a method for an object.\n\n— Charles T. Gray (@cantabile) March 27, 2019\n\nafter a cursory look at UseMethod documentation\nRecently someone, I think it was @kiersi, was asking on twitter how people learn. Today I learnt that I like to play first, ask questions of the documentation after.\nMike Penguin said something about UseMethod on twitter, so I thought I’d start there.\n\n\nOnce I realized that myfun <- function(x, …) UseMethod(“myfun”) is the boilerplate needed I was away. It does magic so that the methods you write i.e. myfun.myclass work like myfun(x) where class(x) includes“my class”\n\n— Michael Sumner (@mdsumner) March 27, 2019\n\n\n\n# i guess i need an object for my function to act on\nfluffyduck <- \"i am a duck\"\n\n# i wonder if you can define your own class?\nclass(fluffyduck) <- \"duck\"\nclass(fluffyduck)\n\n\n[1] \"duck\"\n\n# the UseMethod documentation said the method needs to act on an object\nis.object(fluffyduck)\n\n\n[1] TRUE\n\n# make a function \nfirstquack <- function() {cat(\"quack\")}\n\n# see if it works\nfirstquack()\n\n\nquack\n\n\n\n# but this throws an error\nUseMethod(\"firstquack\", duck)\n\n\nError in eval(expr, envir, enclos): object 'duck' not found\n\n# okay, time to look to the tubes for help\n\n\n\nmake a duck quack, with a little help from Josiah\n\n\nThis! I wrote a post about it and used my PR to janitor as an example. https://t.co/Vn7H3BAQjm\n\n— Josiah Parry (@JosiahParry) March 28, 2019\n\nJosiah’s post was most helpful, indeed. These are my notes.\n\n\n# start by creating a \"generic\" function\nquack <- function(says_the_duck, greeting = \"quack!\") {\n  UseMethod(\"quack\")\n}\n\n\n\nThe generic function seems like an instantiation step. I read this as, I will create a function called this that I can control how it behaves for different classes.\n\n\nquack() # okay, same error as josiah's, so far so good\n\n\nError in UseMethod(\"quack\"): no applicable method for 'quack' applied to an object of class \"NULL\"\n\nSidenote, set chunk option error=TRUE to display code and output for an error.\nMakes sense that this throws an error, we haven’t told it how to behave for anything yet.\n\n\n# set up a default method\nquack.default <-\n  function(says_the_duck = \"quack!\",           greeting = \"quack! \") {\n    print(paste0(greeting, says_the_duck))\n    cat(\"said the duck\")\n  }\n\n# check this default works for anything\nquack(NULL) # yay! it quacked on NULL\n\n\n[1] \"quack! \"\nsaid the duck\n\nquack() # and no argument?\n\n\n[1] \"quack! quack!\"\nsaid the duck\n\nquack(\"i'm a duck\") # a string?\n\n\n[1] \"quack! i'm a duck\"\nsaid the duck\n\n# now to make a fluffyduck-class object\nfluffyduck <- \"i am fluffy\" # create an object\nclass(fluffyduck) <- \"fluffyduck\" # set class of object\n\n# trying this before referring back to the post\nquack.fluffyduck <- function(says_the_duck, greeting = \"quack! \") {\n  print(paste0(greeting, says_the_duck))\n  cat(\"said the fluffy duck\\n\")\n}\n\n# does the duck quack?\nquack(fluffyduck)\n\n\n[1] \"quack! i am fluffy\"\nsaid the fluffy duck\n\n# try another object\nanother_fluffy_duck <- \"i am the fluffiest!\"\n\n# test default\nquack(another_fluffy_duck)\n\n\n[1] \"quack! i am the fluffiest!\"\nsaid the duck\n\n# but this duck is also fluffy!\nclass(another_fluffy_duck) <- \"fluffyduck\"\nquack(another_fluffy_duck)\n\n\n[1] \"quack! i am the fluffiest!\"\nsaid the fluffy duck\n\n# now to test changing my default greeting, to understand how to parse other arguments\nquack(another_fluffy_duck, greeting = \"a most fluffy day to you, \")\n\n\n[1] \"a most fluffy day to you, i am the fluffiest!\"\nsaid the fluffy duck\n\nstuff I still don’t get\nI don’t understand what all the words mean in these definitions of S3 and S4.\n\n4 works similarly to S3, but is more formal. There are two major differences to S3. S4 has formal class definitions, which describe the representation and inheritance for each class, and has special helper functions for defining generics and methods. S4 also has multiple dispatch, which means that generic functions can pick methods based on the class of any number of arguments, not just one. - Advanced R\n\nDoes multiple dispatch mean that the method can be conditional on the class of more than one argument?\nThis was fun; despite me finishing with more questions than I began with.\nmeritget\nMuch obliged to @jacinta for suggesting I update; the internet’s highest honour, gif-phrased praise.\n\n\nFluffy duck! :) pic.twitter.com/9HUPVaXAL4\n\n— Dr Jenny Richmond (@JenRichmondPhD) March 28, 2019\n\na duck for maelle\n\n\n# a duck for maelle!\nmaelles_duck <- \"je suis une cane\"\nclass(maelles_duck) <- \"frenchduck\"\n\n# french ducks speak in french\nquack.frenchduck <- function(says_the_duck, greeting = \"coin! \") {\n  print(paste0(greeting, says_the_duck))\n  cat(\"dit la cane\\n\")\n}\n\n# coin?\nquack(maelles_duck)\n\n\n[1] \"coin! je suis une cane\"\ndit la cane\n\n\n\n\n",
    "preview": {},
    "last_modified": "2023-03-30T10:26:09+02:00",
    "input_file": {}
  }
]
