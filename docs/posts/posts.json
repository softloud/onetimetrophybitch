[
  {
    "path": "posts/2022-07-09-ikigai/",
    "title": "Discipline matters more than effort",
    "description": "Data visualisations that jostle in my mind hearing the usual early career advice",
    "author": [
      {
        "name": "Dr. Charles T. Gray",
        "url": "https://softloud.github.io/onetimetrophybitch/about.html"
      }
    ],
    "date": "2022-07-09",
    "categories": [],
    "contents": "\n\nContents\nwhat was true\nthen, ain’t necessarily so, now\nyears\nbetween opportunities in some disciplines\nprecarious\nacademic employment is still a privilege\ni’m a pragmatist\nikigai\n\nAdvice to early career researchers is variously given along the lines\nof: publish as much as possible; contribute to the discipline’s\ncommunity; participate in the department with teaching and seminars.\nAlso consider internships, consulting, writing blogposts, and\ncommunicating research to the public.\nWhat is often skimmed over, if addressed at all, is the\nextraordinarily wide disparity of opportunity between disciplines\nagainst a backdrop of worsening working conditions for everyone.\nHaving graduated with a thesis in film musicology first, and then a\nPhD in mathematical science, I have been through both experiences\nillustrated in the following visualisation.\n\n\nShow code\n\n# get parameters for plot\nlibrary(parameterpal)\n\ndiscipline_a <- beta_pal(0.6, 0.3, 0.8)\ndiscipline_b <- beta_pal(0.2, 0.1, 0.8)\n\n\n\n\nShow code\n\n# plot function\nset.seed(42)\nlibrary(tidyverse)\nlibrary(viridis)\n\nobs <- 100\n\n\n\nsimdat <- \n    tibble(\n        x = rbeta(obs, discipline_a[[1]], discipline_a[[2]]),\n        discipline = \"A\"\n    ) %>%   \n    bind_rows(\n        tibble(\n            x = rbeta(obs, discipline_b[[1]], discipline_b[[2]]),\n            discipline = \"B\"\n        ) \n    ) \n\nquants <-    \n    simdat %>% \n    group_by(discipline) %>% \n    summarise(\n        first = quantile(x, 0.25),\n        second = quantile(x, 0.5),\n        third = quantile(x, 0.75)\n    )\n\n\ndisc_plot <- \n    function(simdat, quants) {\n\n\n\nplotdat <- \n    simdat %>% \n    left_join(quants) %>% \n    mutate(\n        effort = case_when(\n            x > third ~ \"Publishes, teaches, seminars, blog, & service\" %>% \n                str_wrap(25),\n            x > second ~ \"Publishes & teaches\",\n            x > first ~ \"Publishes\",\n            TRUE ~ \"Graduates\"\n        )\n    )\n\n\n\n\nplotdat  %>%\n    rename(Effort = effort) %>% \n    ggplot(aes(x = discipline, y = x)) +\n    geom_boxplot(\n        alpha = 0.4\n    ) +\n    geom_jitter(aes(colour = Effort), alpha = 0.7) +\n    labs(\n       \n        x = \"Made up disciplines (these are randomly generated data)\" %>% \n            str_wrap(30),\n        y = \"Totally made up probability of obtaining a domain position\" %>% \n            str_wrap(30)\n        \n    ) +\n    ylim(0, 1) +\n    theme_minimal(\n        base_size = 18,\n        base_family = \"serif\"\n    ) +\n    theme(\n        legend.direction = \"horizontal\",\n        legend.position = \"top\",\n        axis.text.y = element_blank()\n    ) +\n    scale_color_viridis(\n        direction = -1,\n        discrete = TRUE,\n        guide =\n    guide_legend(\n        ncol = 2\n    )\n    )         \n    }\n\n\n\n\nShow code\n\ndisc_plot(simdat, quants) +\n    labs(\n         title = \"Discipline matters more than effort\",\n        subtitle = \"Opportunities vary more between domains of interest than in terms of effort\" %>% \n            str_wrap(45),\n        caption = \"Think of each point as a person; an aspiring scholar with a passion. No matter how hard a scholar in Discipline B optimises within discipline, according to various advice provided by mentors (e.g., teach, publish, contribute to community), that scholar will at best achieve the opportunities available to the lowest quartile of Discipline A.\" %>% \n            str_wrap(80)\n    )\n\n\n\nwhat was true then,\nain’t necessarily so, now\nI was told a lot of things that did not hold true: a high distinction\nguarantees PhD scholarship; recruiters would contact so much it would be\nannoying; an undergraduate degree from a reputable university should\nprovide the foundation of a comfortable middle-class life. I think,\nhowever, these things were true for the people who said these\nthings.\nWhy have things changed? So many reasons. For example, in Australia,\nuniversities are financially incentivised to produce postgraduates,\neffectively regardless of career outcomes. The result is a lot more\npostgraduates; “Ah, the PhD bubble”, commented a professor to me in the\ntea room one day.\nIf I assume the things I’ve been told were true, then there was not\nonly higher likelihood of obtaining a position, but also less of a\npenalty between disciplines, when the person providing this advice\nformed their opinions.\n\n\nShow code\n\n# adjustment for opportunity \ntime_a <- beta_pal(0.6 + 0.1, 0.2, 0.6)\ntime_b <- beta_pal(0.2 + 0.5, 0.1, 0.8)\n\n# randomly generate some data\ntimedat <- \n    tibble(\n        x = rbeta(obs, time_a[[1]], time_a[[2]]),\n        discipline = \"A\",\n        timepoint = \"Some decades ago\"\n    ) %>%   \n    bind_rows(\n        tibble(\n            x = rbeta(obs, time_b[[1]], time_b[[2]]),\n            discipline = \"B\",\n        timepoint = \"Some decades ago\"\n        ) \n    ) \n\ntime_quants <-\n        timedat %>% \n    group_by(discipline) %>% \n    summarise(\n        first = quantile(x, 0.25),\n        second = quantile(x, 0.5),\n        third = quantile(x, 0.75)\n    )\n\n\n# combine with original dataset\n\ntime_obs <-\n    simdat %>% \n    mutate(\n        timepoint = \"Now\" \n    ) %>% \n    bind_rows(timedat) %>% \n    mutate(\n        timepoint = fct_relevel(timepoint, \"Some decades ago\")\n        \n    )\n    \n\ntime_quants <-\n    time_obs %>% \n     group_by(discipline, timepoint) %>% \n    summarise(\n        first = quantile(x, 0.25),\n        second = quantile(x, 0.5),\n        third = quantile(x, 0.75)\n    )\n\n\n\n\nShow code\n\n    disc_plot(time_obs, time_quants) +\n    facet_wrap(~ timepoint) +\n    labs(\n        title = \"There are more PhD graduates now\",\n        subtitle = \"Opportunity was greater for some fields, some decades ago, and opportunity was more balanced between disciplines\" %>% \n            str_wrap(55)\n    )\n\n\n\nyears between\nopportunities in some disciplines\nA friend found, on graduating from a PhD in literature, that there\nsimply were no postdoctoral positions in the field. Similiarly, when I\nasked the one public service department that had been known to hire\nalgebraists when there would be postdoctoral positions, they could not\nsay. For some disciplines there are far more graduates than there are\npositions, and only some of the top outliers get through.\n\n\nShow code\n\n# set parameters for discipline with almost no opportunity\ndiscipline_c <- beta_pal(0.05, 0.2, 0.8)\n\ndisc_c_obs <-\ntibble(\n        x = rbeta(obs, discipline_c[[1]], discipline_c[[2]]),\n        discipline = \"C\"\n    ) %>% \n    bind_rows(simdat)\n\ndisc_c_quants <- \n    disc_c_obs %>% \n    group_by(discipline) %>% \n summarise(\n        first = quantile(x, 0.25),\n        second = quantile(x, 0.5),\n        third = quantile(x, 0.75)\n    )\n\n\n\n\nShow code\n\ndisc_plot(disc_c_obs, disc_c_quants) +\n    labs(\n        title = \"No matter how hard you try\",\n        subtitle = \"In some disciplines, there is almost no chance of obtaining a domain position\" %>% \n            str_wrap(45)\n    )\n\n\n\nIn addition, administrative procedures often cause delays, even when\ngrants have been approved and everyone is in agreement. It is\nexceedingly difficult to weather these economic troughs without family\nmembers to fall back on. Harder still, creeping self doubt.\nprecarious\nacademic employment is still a privilege\nUntil my current position, academia had best working\nconditions I have ever experienced. My postdoctoral position,\nlast year, was the first time in my life I had a wage.\nI turned 42 recently. First time in my life I have had\npaid sick leave. First time I didn’t have to\nwork every weekend. The sessional work I did in\nacademia, prior to finishing my studies, was better than casual work I\ncould obtain otherwise. And casual work, dear reader, was all I could\nget.\nThe opportunities to mingle with fascinating people with fascinating\nstories about science were unparalleled. Travel was such a gift; I’d\nnever much been able to afford to leave the country, or stay in hotels.\nAll in all, I loved my time in academia. I sought a position in\nconsulting because I need greater stability than academia can afford to\nmanage complex post-traumatic stress disorder.\nI am not saying that working conditions for early career researchers\nare good. I tend to gesture at the slow demise of neoliberalism, how it\nis causing tectonic shifts in working conditions that are stratifying\nsociety into two classes: those who are serviced; and those who provide\nservices. Another might point to the pandemic, or other drivers. Point\nis what used to be comfortable occupations have shifted into the\nprecariat class. Eroding working conditions for academics are in a\ncontext of eroding working conditions for most occupations.\ni’m a pragmatist\nI’m certainly not the cleverest mathematician, nor a programmer with\na deep understanding of technique. I find research anxiety inducing. I\nneed to be pragmatic about where my energy levels are at for effort, and\nconsider where this will place me in the quartiles of my chosen\ndiscipline. Suppose my effort is in the middle; I certainly don’t feel\nI’ve optimised being an early career researcher.\nI didn’t choose to what I’m good at, nor what I loved. I switched\nfrom pure mathematics to statistics to data science as I formed the\nperception of opportunity illustrated in the visualisations in this\npost. I knew I could not weather being without income. I am also tired\nand do not wish to reinvent myself again anytime soon. I had to ensure\nmy postgraduate studies would lead to employment using the domain I was\ntrained in.\n\n\nShow code\n\n# suppose i am in the second quartile of effort\nme <- \nsimdat %>% \n    left_join(quants) %>% \n    filter(\n        x > (first + 0.05), \n            x < (second - 0.05), \n            discipline == \"A\") %>% \n    sample_n(1) %>% \n    select(x, discipline) %>% \n    mutate(label = \"Me\")\n\n\n\n\nShow code\n\ndisc_plot(simdat, quants) +\n    geom_text(\n        data = me,\n        aes(label = label),\n        size = 5,\n        family = \"serif\"\n    ) + \n    labs(\n        title = \"I'm no outlier\",\n        subtitle = \"Suppose I'm somewhere in the middle when it comes to effort\" %>% str_wrap(45)\n    )\n\n\n\nikigai\nAlthough this post might sound like one of necessary gloom; for me,\nthere is little gloom because I optimised along these paths. I didn’t\nset out to work in data science, I began with an interest in\nmathematics. It is in data science, however, I’ve been able to indulge\nso many other unexpected interests; I use my writing skills more than I\nexpected, for example. I don’t think my job description will stay fixed;\nam approaching with curiosity about where my postgraduate studies will\ntake me next.\nThe lesson, for me, was to embrace not defining myself as any one\nthing, and not to focus on what I think I’m good at. I am not a\nmathematician, nor a programmer, nor a piano teacher. Today I aspire to\nbe a mathematical scientist, but who knows what I’ll aspire to be\ntomorrow.\nMaybe I’ll never know what I’m good at, but I hope I continue to\nsurprise myself.\n\n\n\n",
    "preview": "posts/2022-07-09-ikigai/ikigai_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2022-07-11T15:31:58+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-29-lists/",
    "title": "list and unlist",
    "description": "In which I continue to be confused about ::unlist, but manage to join two lists, as required",
    "author": [
      {
        "name": "Charles T. Gray",
        "url": "https://softloud.github.io/onetimetrophybitch/about.html"
      }
    ],
    "date": "2021-03-29",
    "categories": [
      "codeflow"
    ],
    "contents": "\n\n\n# pkgs used\nlibrary(tidyverse)\n\n\n\n\n\nfirst_list <-\n  list(\n    a = letters[1:3],\n    b = \"mittens\",\n    c = c(TRUE, FALSE),\n    d = rnorm(4)\n  )\n\nsecond_list <- \n  list(\n    e = \"buttons\",\n    f = letters[1:5],\n    g = runif(2)\n  )\n  \n\n# if I have a list(list, list) how do I get list of the elmenets of hte list? \n# Elements of first list as elements,\n# and elements of second list as elements?\n\nunlist(first_list, second_list) %>% \n  dim()\n\n\nNULL\n\n# huh dim?\n\nunlist(first_list, second_list) %>% \n  class()\n\n\n[1] \"character\"\n\n# character?!\n\nunlist(first_list, second_list)\n\n\n                  a1                   a2                   a3 \n                 \"a\"                  \"b\"                  \"c\" \n                   b                   c1                   c2 \n           \"mittens\"               \"TRUE\"              \"FALSE\" \n                  d1                   d2                   d3 \n\"-0.658853976666822\"  \"-1.29571869155379\" \"-0.541580614619811\" \n                  d4 \n\"-0.150846740435645\" \n\n# oh it made everything flat, that's not what I want. I still want the elements \n# to remain lists, what about this recursive argument?\n\nunlist(first_list, second_list, recursive = FALSE) \n\n\n                  a1                   a2                   a3 \n                 \"a\"                  \"b\"                  \"c\" \n                   b                   c1                   c2 \n           \"mittens\"               \"TRUE\"              \"FALSE\" \n                  d1                   d2                   d3 \n\"-0.658853976666822\"  \"-1.29571869155379\" \"-0.541580614619811\" \n                  d4 \n\"-0.150846740435645\" \n\n# okay, maybe I'm overthinking this, what happens if I make a list of two lists\nlist(first_list, second_list)\n\n\n[[1]]\n[[1]]$a\n[1] \"a\" \"b\" \"c\"\n\n[[1]]$b\n[1] \"mittens\"\n\n[[1]]$c\n[1]  TRUE FALSE\n\n[[1]]$d\n[1] -0.6588540 -1.2957187 -0.5415806 -0.1508467\n\n\n[[2]]\n[[2]]$e\n[1] \"buttons\"\n\n[[2]]$f\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\n[[2]]$g\n[1] 0.08550033 0.32802539\n\n# ugh, no I think I ended up with a list of 2 lists\nlist(first_list, second_list) %>% \n  str()\n\n\nList of 2\n $ :List of 4\n  ..$ a: chr [1:3] \"a\" \"b\" \"c\"\n  ..$ b: chr \"mittens\"\n  ..$ c: logi [1:2] TRUE FALSE\n  ..$ d: num [1:4] -0.659 -1.296 -0.542 -0.151\n $ :List of 3\n  ..$ e: chr \"buttons\"\n  ..$ f: chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n  ..$ g: num [1:2] 0.0855 0.328\n\n# see I have a list of 4 and a list of 3, I want a list of 7, not a list of 2 \n# comprising 4 and 3 ugh\n\n# can I use map to extract the elements?\nmap(first_list, 1)\n\n\n$a\n[1] \"a\"\n\n$b\n[1] \"mittens\"\n\n$c\n[1] TRUE\n\n$d\n[1] -0.658854\n\n# how is this different from first list?\nfirst_list\n\n\n$a\n[1] \"a\" \"b\" \"c\"\n\n$b\n[1] \"mittens\"\n\n$c\n[1]  TRUE FALSE\n\n$d\n[1] -0.6588540 -1.2957187 -0.5415806 -0.1508467\n\n# oh that's not what I want\n# fuck me, I'm going to look this up on the tubes now.\n\n\n\nAnd switch to a post. This is proving to be more involved than I thought.\nThis post on stackoverflow suggests using ::append, despite the function saying it is for vectors. Worth a try.\n\n\nappend(first_list, second_list)\n\n\n$a\n[1] \"a\" \"b\" \"c\"\n\n$b\n[1] \"mittens\"\n\n$c\n[1]  TRUE FALSE\n\n$d\n[1] -0.6588540 -1.2957187 -0.5415806 -0.1508467\n\n$e\n[1] \"buttons\"\n\n$f\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\n$g\n[1] 0.08550033 0.32802539\n\n# compare with \nfirst_list\n\n\n$a\n[1] \"a\" \"b\" \"c\"\n\n$b\n[1] \"mittens\"\n\n$c\n[1]  TRUE FALSE\n\n$d\n[1] -0.6588540 -1.2957187 -0.5415806 -0.1508467\n\nsecond_list\n\n\n$e\n[1] \"buttons\"\n\n$f\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\n$g\n[1] 0.08550033 0.32802539\n\nHuh, well, there you go. So a base function to the rescue.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-14T17:05:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-10-24-incorrigible-tidyvert/",
    "title": "incorrigible tidy::vert",
    "description": "a song with %>% references",
    "author": [
      {
        "name": "Charles T. Gray",
        "url": "https://twitter.com/cantabile"
      }
    ],
    "date": "2019-10-24",
    "categories": [
      "music"
    ],
    "contents": "\n\nContents\nincorrigible tidy::vert %>%  exegesis()\nthe %>% operator in the R language\nWhat is an operator?\nWhat is a composite?\n\nWhy do I love to %>%?\nincorrigible tidy::vert %>%  lyrics()\niphone balanced on music stand quality recording\n\nincorrigible tidy::vert %>%  exegesis()\n\nThis post was adapted for inclusion in a joint publication of mathematically-informed artworks engaging with Magritte’s pipe, an icon of surrealism. This manuscript is from a working group of researchers who met at the 2019 Heidelberg Laureate Forum.\n\n\nThank you, Laura Ación, Hao Ye, and James Goldie for checking the maths, and for the reflections on %>%.\n\nIn his 1929 surrealist painting, The Treachery of Images, René Magritte declares Ceci n’est pas une pipe (This is not a pipe). In so doing, he highlights this is but an image, a representation, of a pipe, not truly a pipe itself.\n\nThe Treachery of Images, René Magritte, 1929. Image source: wikipedia.\nI recently wrote a song with lots of references to R and the tidyverse:: metapackage(Wickham 2017).\nI didn't mean to %>% your bubble\nI'm just an incorrigible tidy::vert\nIn this post, I’ll unpack the pipe operator, %>%, that features throughout the lyrics.\nthe %>% operator in the R language\n\n\n\nFigure 1: Image source: magritrr:: GitHub repository.\n\n\n\nThe %>% pipe operator is the first major concept introduced in the programming section, following exploratory data analysis and data wrangling, of Wickham’s R for Data Science (Grolemund and Wickham 2017).\nWith Stefan Milton Bache’s magrittr::(Bache and Wickham 2014) package,\n\n\n# f(x) is equivalent to x %>% f() with magrittr::\n\nlibrary(magrittr)\n\n# f(x)\nround(3.1)\n\n\n[1] 3\n\n# is equivalent to x %>% f()\n\n3.1 %>% round()\n\n\n[1] 3\n\nWhat is an operator?\nWe often forget that operators are, themselves, functions.\nBrian A. Davey’s MAT4GA General Algebra coursebook (what I have on hand) provides this definition.\nFor \\(n \\in \\mathbb N_0 := \\mathbb N \\cup \\{ 0\\}\\), a map \\(f : A^n \\to A\\) is called an n-ary operation on A.\nFor example, \\(+\\) is a function that takes two arguments, numbers, and returns a single number. Algebraically, 3 + 2 = 5 is shorthand for +(3, 2) = 5.\nFor those with formal mathematical training, multiple uses of the %>% operator in a single line of code can be thought of in terms of a coding instantiation of a composite of functions.\nWhat is a composite?\nLet \\(f\\) and \\(g\\) be real functions.\nThe composite of \\(f\\) with \\(g\\) is the real function \\(g \\circ f\\) given by the formula \\((g \\circ f)(x) := g(f(x))\\).\nFor reasons that only made sense to me once I reached graduate-level mathematics, we read a composite of functions from right to left.\nAnd just to break our brains a little, algebraically, the composite operator is a function, so we have \\(g \\circ f = \\circ (f, g)\\)!\nThe pipe, %>%, operator is the R-language equivalent to the composite \\(\\circ\\) operator on real functions.\nWhy do I love to %>%?\nHere is an example with three functions: \\((h \\circ g \\circ f)(x) := h(g(f(x))).\\)\n\n\nset.seed(39)\n\n# get a random sample size between 20 & 100\nsample(seq(20, 100), 1) %>% # this f(x) goes into\n  # generate sample from normal distribution with \n  # mean 50 & sd 0.5\nrnorm(., 50, 0.5) %>% # g, so, now g(f(x), which goes into\n  # calculate mean of that sample\n  mean() # h, so h(g(f(x)))\n\n\n[1] 49.94228\n\nTo see how this is the \\((h \\circ g \\circ f)(x)\\) instantiation, reading from right to left, we take a look at the \\(h(g(f(x)))\\) instantiation of the same code.\n\n\n# this line of code is equivalent to above\n# h(g(f(x))) is less text\n# but the algorithm is harder to ascertain \nmean(rnorm(sample(seq(20, 100), 1), 50, 0.5))\n\n\n[1] 49.98828\n\nThe reader is invited to consider if they agree with the author that it is harder to read the symbols so close together, in this \\(h(g(f(x)))\\) instantiation of the code. Also, arguably more importantly, one does not have the ability to comment each component of the algorithm.\nThere is a downside to the %>%, however. The longer a composite becomes, the more difficult it is to identify errors.\n \nOn the the train Leipzig with snow falling\nAnd my %>%s are getting too long\n\nincorrigible tidy::vert %>%  lyrics()\n\n\n\nCaught the train to Leipzig, snow is falling\nBut I am not nearly done\nRube Goldberging this algorithm\nBut the sampling is off.\n\nI didn't mean to %>% your bubble\nI'm just an incorrible tidy::vert\n\nAnd I'm here to tell ya\nThere's some rhyme and reason\nBut there's a whole lot that can get fucked up\n\nAnd I'm here to tell ya\nThere's scarce rhyme and reason\nSo let's brace for the shitstorm\n\nDon't think I'll unravel\nThe mysteries of the beta distribution\nOn the the train Leipzig with snow falling\nAnd my %>%s are getting too long\n\nBut I didn't mean to %>% your bubble\nI'm just an incorrible tidy::vert\n\nAnd I'm here to tell ya\nThere's some rhyme and reason\nBut there's a whole lot that can get fucked up\n\nAnd I'm here to tell ya\nThere's scarce rhyme and reason\nSo let's brace for the CRANstorm\n\nAnd I didn't mean to %>% your bubble\nLet your flame war flame itself out\nAnd I didn't mean to %>% your bubble\nExcuse Me, Do You Have a Moment \n to Talk About Version Control?\n\nAnd I didn't mean to %>% your bubble\nI'm just an incorrible tidy::vert\nAnd I didn't mean to %>% your bubble\nI'm just an incorrible tidy::vert\n\n\niphone balanced on music stand quality recording\nDon’t say I didn’t warn you about the sound quality.\n\n\n\n\n\nBache, Stefan Milton, and Hadley Wickham. 2014. “Magrittr: A Forward-Pipe Operator for R.”\n\n\nGrolemund, Garrett, and Hadley Wickham. 2017. R for Data Science.\n\n\nWickham, Hadley. 2017. “Tidyverse: Easily Install and Load the ’Tidyverse’.”\n\n\n\n\n",
    "preview": "posts/2019-10-24-incorrigible-tidyvert/pipe-logo.png",
    "last_modified": "2021-12-14T17:05:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-28-quack-quack-said-the-duck/",
    "title": "quack! quack! said the duck",
    "description": "making sense of methods in R",
    "author": [
      {
        "name": "cantabile",
        "url": {}
      }
    ],
    "date": "2019-03-28",
    "categories": [
      "dev"
    ],
    "contents": "\n\nContents\nafter a cursory look at UseMethod documentation\nmake a duck quack, with a little help from Josiah\nstuff I still don’t get\nmeritget\na duck for maelle\n\n\nSome time back, @malco_barrett and I discovered we both had tidyverse::-integrated functions in development for meta-analysis models, specifically models produced by metafor::rma.\nWe started to discuss how to bring together the work we’d done, and then, speaking for myself, I got busy and overwhelmed last year with the general craziness that doing a doctorate is, and this slipped way back on the backburner.\nLast week, however, one of the creators of the broom:: package got in touch with Malcolm about porting the code. And, with the Evidence Synthesis Hackathon imminent, it seems as if the time is nigh. If I’m going to be able to collaborate on this, that means finally getting around to learning about methods in R.\n\n\nCracks metaphoric R knuckles.So, S3. What's that all about?\n\n— Charles T. Gray (@cantabile) March 27, 2019\n\nI think I might find this pedagogically interesting in future, to reflect on where I started today, and where I ended up.\n\n\nJourney begins here: my current impression is that, digging back 8 years ago to my one compsci subject, first year java, S3 is a method for an object.\n\n— Charles T. Gray (@cantabile) March 27, 2019\n\nafter a cursory look at UseMethod documentation\nRecently someone, I think it was @kiersi, was asking on twitter how people learn. Today I learnt that I like to play first, ask questions of the documentation after.\nMike Penguin said something about UseMethod on twitter, so I thought I’d start there.\n\n\nOnce I realized that myfun <- function(x, …) UseMethod(“myfun”) is the boilerplate needed I was away. It does magic so that the methods you write i.e. myfun.myclass work like myfun(x) where class(x) includes“my class”\n\n— Michael Sumner (@mdsumner) March 27, 2019\n\n\n\n# i guess i need an object for my function to act on\nfluffyduck <- \"i am a duck\"\n\n# i wonder if you can define your own class?\nclass(fluffyduck) <- \"duck\"\nclass(fluffyduck)\n\n\n[1] \"duck\"\n\n# the UseMethod documentation said the method needs to act on an object\nis.object(fluffyduck)\n\n\n[1] TRUE\n\n# make a function \nfirstquack <- function() {cat(\"quack\")}\n\n# see if it works\nfirstquack()\n\n\nquack\n\n\n\n# but this throws an error\nUseMethod(\"firstquack\", duck)\n\n\nError in eval(expr, envir, enclos): object 'duck' not found\n\n# okay, time to look to the tubes for help\n\n\n\nmake a duck quack, with a little help from Josiah\n\n\nThis! I wrote a post about it and used my PR to janitor as an example. https://t.co/Vn7H3BAQjm\n\n— Josiah Parry (@JosiahParry) March 28, 2019\n\nJosiah’s post was most helpful, indeed. These are my notes.\n\n\n# start by creating a \"generic\" function\nquack <- function(says_the_duck, greeting = \"quack!\") {\n  UseMethod(\"quack\")\n}\n\n\n\nThe generic function seems like an instantiation step. I read this as, I will create a function called this that I can control how it behaves for different classes.\n\n\nquack() # okay, same error as josiah's, so far so good\n\n\nError in UseMethod(\"quack\"): no applicable method for 'quack' applied to an object of class \"NULL\"\n\nSidenote, set chunk option error=TRUE to display code and output for an error.\nMakes sense that this throws an error, we haven’t told it how to behave for anything yet.\n\n\n# set up a default method\nquack.default <-\n  function(says_the_duck = \"quack!\",           greeting = \"quack! \") {\n    print(paste0(greeting, says_the_duck))\n    cat(\"said the duck\")\n  }\n\n# check this default works for anything\nquack(NULL) # yay! it quacked on NULL\n\n\n[1] \"quack! \"\nsaid the duck\n\nquack() # and no argument?\n\n\n[1] \"quack! quack!\"\nsaid the duck\n\nquack(\"i'm a duck\") # a string?\n\n\n[1] \"quack! i'm a duck\"\nsaid the duck\n\n# now to make a fluffyduck-class object\nfluffyduck <- \"i am fluffy\" # create an object\nclass(fluffyduck) <- \"fluffyduck\" # set class of object\n\n# trying this before referring back to the post\nquack.fluffyduck <- function(says_the_duck, greeting = \"quack! \") {\n  print(paste0(greeting, says_the_duck))\n  cat(\"said the fluffy duck\\n\")\n}\n\n# does the duck quack?\nquack(fluffyduck)\n\n\n[1] \"quack! i am fluffy\"\nsaid the fluffy duck\n\n# try another object\nanother_fluffy_duck <- \"i am the fluffiest!\"\n\n# test default\nquack(another_fluffy_duck)\n\n\n[1] \"quack! i am the fluffiest!\"\nsaid the duck\n\n# but this duck is also fluffy!\nclass(another_fluffy_duck) <- \"fluffyduck\"\nquack(another_fluffy_duck)\n\n\n[1] \"quack! i am the fluffiest!\"\nsaid the fluffy duck\n\n# now to test changing my default greeting, to understand how to parse other arguments\nquack(another_fluffy_duck, greeting = \"a most fluffy day to you, \")\n\n\n[1] \"a most fluffy day to you, i am the fluffiest!\"\nsaid the fluffy duck\n\nstuff I still don’t get\nI don’t understand what all the words mean in these definitions of S3 and S4.\n\n4 works similarly to S3, but is more formal. There are two major differences to S3. S4 has formal class definitions, which describe the representation and inheritance for each class, and has special helper functions for defining generics and methods. S4 also has multiple dispatch, which means that generic functions can pick methods based on the class of any number of arguments, not just one. - Advanced R\n\nDoes multiple dispatch mean that the method can be conditional on the class of more than one argument?\nThis was fun; despite me finishing with more questions than I began with.\nmeritget\nMuch obliged to @jacinta for suggesting I update; the internet’s highest honour, gif-phrased praise.\n\n\nFluffy duck! :) pic.twitter.com/9HUPVaXAL4\n\n— Dr Jenny Richmond (@JenRichmondPhD) March 28, 2019\n\na duck for maelle\n\n\n# a duck for maelle!\nmaelles_duck <- \"je suis une cane\"\nclass(maelles_duck) <- \"frenchduck\"\n\n# french ducks speak in french\nquack.frenchduck <- function(says_the_duck, greeting = \"coin! \") {\n  print(paste0(greeting, says_the_duck))\n  cat(\"dit la cane\\n\")\n}\n\n# coin?\nquack(maelles_duck)\n\n\n[1] \"coin! je suis une cane\"\ndit la cane\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-14T17:05:08+01:00",
    "input_file": {}
  }
]
