{
  "articles": [
    {
      "path": "about.html",
      "title": "trophybitch",
      "description": "a one-time trophy bitch screams into the void\n",
      "author": [],
      "contents": "\ncurrently working on\n\n\nlibrary(pandan)\n\npandan_view(distill=TRUE)\n\n\n\n\npublications\nSee references at bottom of this page for citation details.\ntitle\ndiscipline\ndescription\ncode::proof: Prepare for most weather conditions(Gray 2019)\nmetaprogramming\nsecond paper from thesis, accepted to springer computer science proceedings something something, metaprogramming\nTruth, Proof, and Reproducibility: There’s no counter-attack for the codeless\nmetamathematics\nfirst paper from current thesis has been accepted into springer computer proceedings something something, metamathematics(Gray and Marwick 2019)\nThe Homomorphism Lattice Induced by a Finite Algebra\nabstract algebra\nThe publication of my honours (masters-level) thesis in abstract algebra. Authorship is alphabetical and equal in mathematics. Brian and Jane did a great deal of work on the final paper. But in my thesis, the proofs were all (but two small introductory proofs Brian wrote for completeness) my own. (Davey, Gray, and Pitkethly 2018)\nProfiling for Profit\nmarketing\noddly enough, an award-winning consumer behaviour paper, best in the business ethics track (Harrison and Gray 2010; Harrison and Gray 2012)\neviatlas::\necology\nwrote one paragraph and contributed to discussion on this ecology project(Haddaway et al. 2019)\ntodo:look up\npsychology\nspent two deep-dive days conjuring a package out of an equation for the Misinformation Lab, and two co-authored papers are submitted\nCoding of Kindness(Gray et al. 2019)\nopen science\na rephrasing of the Code of Conduct, which did not win over the people I was trying to communicate with, but did mean that other survivors reached out, and that was quite lovely\nsome other cool shit i did 2\nMost recent first.\nreprofail seminar - long version\nreadme for talk with abstract\n\n\nheidelberg laureate forum\nIt was a delight to participate in the opening of the Heidelberg Laureate Forum, where the laureates of mathematics and computer science meet the next generation.\nI’ve cued this video to my presentation on the algebra of composition.\n\n\nThere’s no Nobel prize in mathematics and computer science. Instead, there is the Turing award, the Fields medal, and the Abel prize. Each year the Heidelberg Laureate Forum Foundation gathers these laureates of mathematics and computing, along with two hundred talented early-career researchers, and science writers, for a week of lectures, workshops, and events designed to foster conversation and ideas.\nIt was a gift to present at the opening ceremony and have that introduction; I wasn’t in want of conversation for the entire event. I got to meet so many interesting people.\nSlides for the presentation can be found here.\ncode like a girl tour\ncheck out twitter reel from the tour\nand the event\n\nuseR! workshop\n\n\nmathbassador gray\n\n\n\n\n\nDavey, Brian A., Charles T. Gray, and Jane G. Pitkethly. 2018. “The Homomorphism Lattice Induced by a Finite Algebra.” Order 35 (2): 193–214. https://doi.org/10.1007/s11083-017-9426-3.\n\n\nGray, Charles T. 2019. “: Prepare for Most Weather Conditions.” http://arxiv.org/abs/1910.06964.\n\n\nGray, Charles T., and Ben Marwick. 2019. “Truth, Proof, and Reproducibility: There’s No Counter-Attack for the Codeless.” arXiv:1907.05947 [Math], July. http://arxiv.org/abs/1907.05947.\n\n\n———. 2019. “Truth, Proof, and Reproducibility: There’s No Counter-Attack for the Codeless.” arXiv:1907.05947 [Math], July. http://arxiv.org/abs/1907.05947.\n\n\n———. 2019. “Truth, Proof, and Reproducibility: There’s No Counter-Attack for the Codeless.” arXiv:1907.05947 [Math], July. http://arxiv.org/abs/1907.05947.\n\n\nGray, Charles T., Ben Marwick, Jen Richmond, Emily Kothe, Mathew Ling, and Brian Knaus. 2019. “Coding of Kindness: Let’s Figure Out How to Be Better Humans to Each Other.” Coding of Kindness. https://softloud.github.io/codingofkindness/.\n\n\n———. 2019. “Coding of Kindness: Let’s Figure Out How to Be Better Humans to Each Other.” Coding of Kindness. https://softloud.github.io/codingofkindness/.\n\n\nHaddaway, Neal R., Andrew Feierman, Matthew J. Grainger, Charles T. Gray, Ezgi Tanriver-Ayder, Sanita Dhaubanjar, and Martin J. Westgate. 2019. “EviAtlas: A Tool for Visualising Evidence Synthesis Databases.” Environmental Evidence 8 (1): 22. https://doi.org/10.1186/s13750-019-0167-1.\n\n\nHarrison, Paul, and Charles Gray. 2010. “The Ethical and Policy Implications of Profiling ‘Vulnerable’ Customers: Implications of Customer Profiling.” International Journal of Consumer Studies 34 (4): 437–42. https://doi.org/10.1111/j.1470-6431.2010.00873.x.\n\n\nHarrison, Paul, and Charles Ti Gray. 2012. Profiling for Profit : A Report on Target Marketing and Profiling Practices in the Credit Industry. Consumer Action Law Centre.\n\n\n\n\n",
      "last_modified": "2021-03-29T18:34:39+01:00"
    },
    {
      "path": "chapter-2.html",
      "title": "chapter 2",
      "description": "exercises from chapter 2 statistical rethinking\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\neasy\n2E1\n2E2\n2E3\n2E4\n\nmedium\n2M1\n2M2\n2M3\n2M4\n2M5\n2M6\n2M7\n\nhard\n2H1\n2H2\n2H3\n\n\n\n\n# packages used\nlibrary(tidyverse)\nlibrary(gt)\n\n\n\nChecking solutions with this helpful discussion and this other set of solutions. Yay for open learning.\n\n\npandan::pandan_view(project = \"rethinking\", distill = TRUE, update = FALSE)\n\n\n\n\neasy\n2E1\n\nWhich of the expressions below correspond to the statement: the probability of rain on Monday?\n\nP(rain)\nP(rain|Monday)\nP(Monday|rain)\nP(rain, Monday) / P(Monday)\nAdapting the equation on p. 37 to a more generalised statement, for a parameter of interest \\(\\theta\\) and observations \\(y\\) dependent on that parameter, we have\n\\[\nP(\\theta | y) = \\frac{P(y|\\theta)P(\\theta)}{P(y)} = P(\\theta, y)/P(y)\n\\]\nThen P(rain|Monday) = P(rain, Monday) / P(Monday).\nSo, I conclude that 2. and 4. correspond to the statement.\n2E2\nThe following statement corresponds to the expression P(Monday|rain):\nThe probability that it is Monday, given that it is raining.\n2E3\n\nThe probability that it is Monday given that it is raining.\n\nCan be expressed\nP(Monday|rain) = P(rain|Monday)P(Monday)/P(rain)\nSo, the following statements correspond.\nP(Monday|rain) and 4. P(rain|Monday)P(Monday)/P(rain)\n2E4\n\nThe Bayesian statistician Finetti began his book on probablity theory with the declaration: “PROBABILITY DOES NOT EXIST”. What he meant is that probability is a device for describing uncertainty from the perspective ofg an observer with limited knowledge; it has no objective reality. What does it mean to say, “the probability of water is 0.7”?\n\nBased on the observations we have of water and land from globe tossing, the most credible proportion of the globe is approximately 0.7.\nmedium\n2M1\n\nCompute and plot the grid approximate posterior distribution for each of the following sets of observations. In each case, assume a uniform prior for p.\n\nWWW\nWWWL\nLWWLWWW\nWe assume \\[\n\\begin{array}\n\\\\W & \\sim & \\text{binomial}(N, p)\\\\\np & \\sim & \\text{uniform}(0, 1)\n\\end{array}\n\\] where \\(W\\) is the number of water observations and \\(N = L + W\\) is the total number of water and land observations. We only know \\(p\\) is a proportion, so we know that it falls in \\([0,1]\\).\nWe are interested in finding \\[\nP(p|W,L) = P(W,L|p)P(p)/P(W,L)\n\\] where \\(P(p|W,L)\\) is the posterior, \\(P(W,L|p)\\) is the probability of the data, \\(P(W,L)\\) is the prior.\n\nAnd this is Bayes’ theorem. It says the the probability of any particular value of \\(p\\), considering the data is equal to the product of the relative plausibility of the data, conditional on \\(p\\), and the prior plausibility of \\(p\\), divided by the average probability of the data.\n\n\\[\n\\text{Posterior} = \\frac{\n\\text{Probability of the data} \\times \\text{Prior}\n}{\n\\text{Average probability of the data}\n}\n\\]\n\n\nlibrary(tidyverse)\n\n# set number of points for the grid \nn <- 10\n\n# create a grid approximation tableT\nwww <- \n    tibble(\n        # define grid\n        p = seq(0, 1, length.out = n),\n        # compute prior at each parameter value\n        prior = 1\n    ) %>% \n    mutate(\n        # compute the likelihood at each parameter value\n        plausibility = dbinom(3, size = 3, prob = p),\n        # comput the unstandardised posterior\n        unstd_post = plausibility * prior,\n        # standardise the posterior\n        posterior = unstd_post / sum(unstd_post)\n    )\n\n\n\n\n\ngrid_plot <- function(post_df, title_text) {\npost_df %>% \n    ggplot(\n        aes(\n            x = p,\n            y = posterior\n        )\n    ) +\n    geom_line(alpha = 0.4) +\n    geom_point(alpha = 0.8) + \n    labs(title = title_text) + \n        ggthemes::theme_tufte()\n    \n}\n\n\n\nIt makes sense that for www observation, we have a monotonically increasing posterior. Higher values of \\(p\\) are more likely, given we have only observed water.\n\n\ngrid_plot(www, \"w w w\")\n\n\n\n\nNow for the second set of observations, wwwl. This should be slightly more interesting, as there is one land observation, so we know with certainty that \\(p \\neq 1\\), whereas in www, this was the most plausible value for \\(p\\).\n\n\nwwwl <- \n    tibble(\n        # define grid\n        p = seq(0, 1, length.out = n),\n        # compute prior at each parameter value\n        prior = 1\n    ) %>% \n    mutate(\n        # compute the likelihood at each parameter value\n        plausibility = dbinom(3, size = 4, prob = p),\n        # comput the unstandardised posterior\n        unstd_post = plausibility * prior,\n        # standardise the posterior\n        posterior = unstd_post / sum(unstd_post)\n    )\n\ngrid_plot(wwwl, \"w w w l\")\n\n\n\n\n\n\nlwwlwww <- \n    tibble(\n        # define grid\n        p = seq(0, 1, length.out = n),\n        # compute prior at each parameter value\n        prior = 1\n    ) %>% \n    mutate(\n        # compute the likelihood at each parameter value\n        plausibility = dbinom(5, size = 7, prob = p),\n        # comput the unstandardised posterior\n        unstd_post = plausibility * prior,\n        # standardise the posterior\n        posterior = unstd_post / sum(unstd_post)\n    )\n\ngrid_plot(lwwlwww, \"l w w l w w\")\n\n\n\n\n2M2\nWe now assume a prior \\(P: [0,1] \\to \\{0, \\theta\\}\\) such that \\[\np \\mapsto \n\\begin{cases}\n0 & p < 0.5\\\\\n\\theta & p \\geqslant 0.5\n\\end{cases}\n\\] where \\(\\theta \\in \\mathbb R^+\\), and again compute the grid approximations as in 2M1.\nNow I’ve got the general idea of each line of the grid approximation, I’ll now functionalise it.\n\n\ngrid_theta <- function(w, sample_size) {\n  # get a random positive value\n  theta <- runif(1, 1, 10000)\n  \n  # return tibble of grid approx\n     tibble(\n        # define grid\n        p = seq(0, 1, length.out = n),\n        # compute prior at each parameter value\n        prior = if_else(p < 0.5, 0, theta)\n    ) %>% \n    mutate(\n        # compute the likelihood at each parameter value\n        plausibility = dbinom(w, size = sample_size, prob = p),\n        # comput the unstandardised posterior\n        unstd_post = plausibility * prior,\n        # standardise the posterior\n        posterior = unstd_post / sum(unstd_post)\n    )\n}\n\n\n\n\n\n# www\n\ngrid_theta(3, 3) %>% \n  grid_plot(\"w w w, prior = 0 for p < 0.5\")\n\n\n\n\n\n\n# wwwl\n\ngrid_theta(3, 4) %>% \n  grid_plot(\"w w w l, prior = 0 for p < 0.5\")\n\n\n\n\n\n\n# lwwlwww\ngrid_theta(5, 7) %>% \n  grid_plot(\"l w w l w w w, prior = 0 for p < 0.5\")\n\n\n\n\nSince \\[\n\\text{Posterior} = \\frac{\n\\text{Probability of the data} \\times \\text{Prior}\n}{\n\\text{Average probability of the data}\n}\n\\] In all three questions, for \\(p< 0.5\\), the posterior is 0.\nSince the numerator is a product of the probability of the data and the prior, which is set to 0 for \\(p < 0.5\\), and any product containing zero is zero, we have a posterior of 0 for all values \\(p < 0.5\\). That is, where the prior is 0, this will always produce a posterior of 0, regardless of the value of the probability of the data.\n2M3\n\nSuppose there are two globes, one for Earth and one for Mars. The Earth globe is 70% covered in water. The Mars globe is 100% land.\n\nSo, P(water|Earth) = 0.7 and P(land|Mars) = 1.0.\n\nFurther suppose that one of these globes - you don’t know which - was tossed in the air and produced a land observation. Assume each globe was equally likely to be tossed.\n\nSo, P(Earth) = 0.5 and P(Mars) = 0.5.\n\nShow that the posterior probability that the globe was Earth conditional on seeing land is 0.23, that is, P(Earth|land) = 0.23.\n\nWe wish to show that P(Earth|land) = 0.23.\nWell, Bayes’ theorem gives us,\nP(Earth|land) = P(land|Earth)P(Earth)/P(land).\nSo we need to find P(land|Earth), P(Earth), and P(land).\nWe know P(Earth) = 0.5.\nNow P(water|Earth) = 0.7, so P(land|Earth) = 0.3, since there are only two possibilities on Earth.\nFinally, for P(land), we note that, going back to the original generalised notation, \\[\nP(y) = E(P(y|\\theta)) = \\int P(y|\\theta)P(\\theta)d\\theta\n\\] so, since in this example we are dealing with discrete possibilities,\nP(land) = E(P(land|Planet)) = \\(\\displaystyle\\sum_{\\text{Planet } \\in \\{\\text{Earth},\\text{Mars}\\}}\\) P(land|Planet)P(planet) = P(land|Earth) P(Earth) + P(land|Mars) P(Mars).\nThen P(land) is\n\n\n0.3 * 0.5 + 1 * 0.5\n\n\n[1] 0.65\n\nSo, we have P(land|Earth), by Bayes’ theorem, is\n\n\n(0.3 * 0.5)/(0.3 * 0.5 + 1 * 0.5)\n\n\n[1] 0.2307692\n\n2M4\n\nSuppose you have a deck with only three cards.\n\nLet \\(X\\) denote the set of three cards, so \\(|X|=3\\).\n\nAnd each side is either black or white. One card has two black sides. The second card has one black and one white side. The third card has two white sides.\n\nSo, we could say \\(X = \\{BB, BW, WW\\}\\).\n\nSomeone pulls out a card and places it flat on a table. A black side is shown facing up, but you don’t know the colour of the side facing down.\n\nLet \\(y\\) denote the observation \\(B\\). Now, clearly \\(P(B|WW) = 0\\).\n\nUse the counting method from Section 2. This means counting up the ways that each card could produce the observed data.\n\n\nShow that the probability that the other side is also black is 2/3.\n\nWe wish to show that \\(P(BB|B) = 2/3\\).\n\n\ntibble(\n  # possible cards\n  conjecture = c(\"BB\", \"BW\", \"WW\"),\n  # probability of each card\n  p = rep(1 / 3, 3),\n  # ways the card can produce the observation B\n  ways = c(2, 1, 0)\n) %>%\n  # calculate the plausibility\n  mutate(prod = p * ways,\n         plausibility = prod / sum(prod)) %>%\n  gt() %>%\n  cols_label(\n    conjecture = \"possible cards\",\n    p = \"likelihood of drawing card\",\n    ways = \"ways card can produce B\",\n    prod = \"p x ways\",\n    plausibility = \"plausbility - p x ways/sum(p x ways)\"\n  ) %>% \n  data_color(\n    columns = vars(plausibility),\n    colors = scales::col_bin(\n      palette = c(\"#93a1a1\", \"white\"),\n      bins = 2,\n      domain = NULL,\n      reverse = TRUE\n    )\n  ) %>% \n  data_color(\n    columns = vars(conjecture),\n    colors = scales::col_factor(\n      palette = c(\"#93a1a1\", \"white\", \"white\"),\n      domain = NULL\n    )\n  )\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#ccxhrthjzb .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ccxhrthjzb .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ccxhrthjzb .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ccxhrthjzb .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ccxhrthjzb .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ccxhrthjzb .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ccxhrthjzb .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ccxhrthjzb .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ccxhrthjzb .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ccxhrthjzb .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ccxhrthjzb .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ccxhrthjzb .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ccxhrthjzb .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ccxhrthjzb .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ccxhrthjzb .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ccxhrthjzb .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ccxhrthjzb .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#ccxhrthjzb .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ccxhrthjzb .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#ccxhrthjzb .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ccxhrthjzb .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ccxhrthjzb .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ccxhrthjzb .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ccxhrthjzb .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ccxhrthjzb .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ccxhrthjzb .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ccxhrthjzb .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ccxhrthjzb .gt_left {\n  text-align: left;\n}\n\n#ccxhrthjzb .gt_center {\n  text-align: center;\n}\n\n#ccxhrthjzb .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ccxhrthjzb .gt_font_normal {\n  font-weight: normal;\n}\n\n#ccxhrthjzb .gt_font_bold {\n  font-weight: bold;\n}\n\n#ccxhrthjzb .gt_font_italic {\n  font-style: italic;\n}\n\n#ccxhrthjzb .gt_super {\n  font-size: 65%;\n}\n\n#ccxhrthjzb .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\npossible cards\n      likelihood of drawing card\n      ways card can produce B\n      p x ways\n      plausbility - p x ways/sum(p x ways)\n    BB\n      0.3333333\n      2\n      0.6666667\n      0.6666667\n    BW\n      0.3333333\n      1\n      0.3333333\n      0.3333333\n    WW\n      0.3333333\n      0\n      0.0000000\n      0.0000000\n    \n\n2M5\nNow suppose there are four cards \\(\\{BB, BW, WW, BB\\}\\).\nAgain calculate the probability the other side is black.\nThis time I’ll use TeX so I can see how I worked it on paper.\n\\[\n\\begin{array}{cccc}\n\\text{possible card} & \\text{chance of card} & \\text{ways card produces B} & \\text{chance} \\times \\text{ways} & \\text{plausibility (product / $\\Sigma$)}\\\\\n\\hline\nBB & 1/2 & 2 & 1 & 4/5\\\\\nBW & 1/4 & 1 & 1/4 & 1/5\\\\\nWW & 1/4 & 0 & 0 & 0\\\\\n\\hline\n&&&\\Sigma = 5/4\n\\end{array}\n\\]\nSo, the probability the other side is black is\n\n\n4/5\n\n\n[1] 0.8\n\n2M6\n\nImagine the black ink is heavy, and so cards with black sides are heavier than cards with white sides.\n\nSo, P(B) < P(W).\n\nAgain assume there are three cards \\(\\{BB, BW, WW\\}\\). After experimenting a number of times, you conclude that for every way to pull the \\(BB\\) card from the bag, there are 2 ways to pull the BW card, and 3 ways to pull the WW card. Again suppose that a card is pulled and a black side appears face up. Show that the probability the other side is black is now 0.5. Use the counting method, as before.\n\n2M7\n\nAssume againt he original card problem, with a single card showing a black side face up. Before looking at the other side, we draw another card from the bag and lay it face up on the table. The face that is shown on the new card is white. Show that the probability that the first card, the one showing a black side, has black on its other side is now 0.45. Using the counting method, if you can. Hint: Treat this like the sequence of globe tosses, counting all the ways to see each observation, for each possible first card.\n\nhard\n2H1\n\nSuppose there are two species of panda bear. Both are equally common in the wild and live int he sampe places. The look exactly alide and eat the same food, and there is yet no geneetic assay capable of telling them apart. They differ however in their family sizes. Specias A gives bith to twins 10% of the time, otherwise birthing a single infant. Species B births twins 20% of the time, otherwise birhting singleton infants. Assume these numbers are known with certainty, from many years of field research.\n\n\nNow suppose you are managing a captive panda breeding program. You have a new female panda of unknown species, and she has just given birth to twins. What is the probability that her next birth will also be twins?\n\n2H2\n\nRecall all the facts from the problem above.\n\n\nNow compute the probability that the panda we have is from species A, assuming we have observed only the first birth and that it was twins.\n\n2H3\n\nContinuing on from the previous problem, suppose the same panda mother has a second birth and that it is not twins, but a singleton infant.\n\n\nCompute the posterior probability that this panda is species A.\n\n\n\n\n",
      "last_modified": "2021-03-29T18:34:46+01:00"
    },
    {
      "path": "index.html",
      "title": "measured.",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-03-29T18:34:47+01:00"
    },
    {
      "path": "README.html",
      "author": [],
      "contents": "\nonetimetrophybitch\n\n\n",
      "last_modified": "2021-03-29T18:34:47+01:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
