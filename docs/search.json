{
  "articles": [
    {
      "path": "about.html",
      "title": "trophybitch",
      "description": "a one-time trophy bitch screams into the void\n",
      "author": [],
      "contents": "\npublications\nSee references at bottom of this page for citation details.\ntitle\ndiscipline\ndescription\ncode::proof: Prepare for most weather conditions(Gray 2019)\nmetaprogramming\nsecond paper from thesis, accepted to springer computer science proceedings something something, metaprogramming\nTruth, Proof, and Reproducibility: There’s no counter-attack for the codeless\nmetamathematics\nfirst paper from current thesis has been accepted into springer computer proceedings something something, metamathematics(Gray and Marwick 2019)\nThe Homomorphism Lattice Induced by a Finite Algebra\nabstract algebra\nThe publication of my honours (masters-level) thesis in abstract algebra. Authorship is alphabetical and equal in mathematics. Brian and Jane did a great deal of work on the final paper. But in my thesis, the proofs were all (but two small introductory proofs Brian wrote for completeness) my own. (Davey, Gray, and Pitkethly 2018)\nProfiling for Profit\nmarketing\noddly enough, an award-winning consumer behaviour paper, best in the business ethics track (Harrison and Gray 2010; Harrison and Gray 2012)\neviatlas::\necology\nwrote one paragraph and contributed to discussion on this ecology project(Haddaway et al. 2019)\ntodo:look up\npsychology\nspent two deep-dive days conjuring a package out of an equation for the Misinformation Lab, and two co-authored papers are submitted\nCoding of Kindness(Gray et al. 2019)\nopen science\na rephrasing of the Code of Conduct, which did not win over the people I was trying to communicate with, but did mean that other survivors reached out, and that was quite lovely\nsome other cool shit i did 2\nMost recent first.\nreprofail seminar - long version\nreadme for talk with abstract\n\n\nheidelberg laureate forum\nIt was a delight to participate in the opening of the Heidelberg Laureate Forum, where the laureates of mathematics and computer science meet the next generation.\nI’ve cued this video to my presentation on the algebra of composition.\n\n\nThere’s no Nobel prize in mathematics and computer science. Instead, there is the Turing award, the Fields medal, and the Abel prize. Each year the Heidelberg Laureate Forum Foundation gathers these laureates of mathematics and computing, along with two hundred talented early-career researchers, and science writers, for a week of lectures, workshops, and events designed to foster conversation and ideas.\nIt was a gift to present at the opening ceremony and have that introduction; I wasn’t in want of conversation for the entire event. I got to meet so many interesting people.\nSlides for the presentation can be found here.\ncode like a girl tour\ncheck out twitter reel from the tour\nand the event\n\nuseR! workshop\n\n\nmathbassador gray\n\n\n\n\n\nDavey, Brian A., Charles T. Gray, and Jane G. Pitkethly. 2018. “The Homomorphism Lattice Induced by a Finite Algebra.” Order 35 (2): 193–214. https://doi.org/10.1007/s11083-017-9426-3.\n\n\nGray, Charles T. 2019. “: Prepare for Most Weather Conditions.” http://arxiv.org/abs/1910.06964.\n\n\nGray, Charles T., and Ben Marwick. 2019. “Truth, Proof, and Reproducibility: There’s No Counter-Attack for the Codeless.” arXiv:1907.05947 [Math], July. http://arxiv.org/abs/1907.05947.\n\n\nGray, Charles T., Ben Marwick, Jen Richmond, Emily Kothe, Mathew Ling, and Brian Knaus. 2019. “Coding of Kindness: Let’s Figure Out How to Be Better Humans to Each Other.” Coding of Kindness. https://softloud.github.io/codingofkindness/.\n\n\nHaddaway, Neal R., Andrew Feierman, Matthew J. Grainger, Charles T. Gray, Ezgi Tanriver-Ayder, Sanita Dhaubanjar, and Martin J. Westgate. 2019. “EviAtlas: A Tool for Visualising Evidence Synthesis Databases.” Environmental Evidence 8 (1): 22. https://doi.org/10.1186/s13750-019-0167-1.\n\n\nHarrison, Paul, and Charles Gray. 2010. “The Ethical and Policy Implications of Profiling ‘Vulnerable’ Customers: Implications of Customer Profiling.” International Journal of Consumer Studies 34 (4): 437–42. https://doi.org/10.1111/j.1470-6431.2010.00873.x.\n\n\nHarrison, Paul, and Charles Ti Gray. 2012. Profiling for Profit : A Report on Target Marketing and Profiling Practices in the Credit Industry. Consumer Action Law Centre.\n\n\n\n\n",
      "last_modified": "2021-07-23T10:35:00+01:00"
    },
    {
      "path": "chapter-2.html",
      "title": "chapter 2",
      "description": "exercises from chapter 2 statistical rethinking\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\neasy\n2E1\n2E2\n2E3\n2E4\n\nmedium\n2M1\n2M2\n2M3\n2M4\n2M5\n2M6\n2M7\n\nhard\n2H1\n2H2\n2H3\n\n\n\n\n# packages used\nlibrary(tidyverse)\nlibrary(gt)\n\n\n\nChecking solutions with this helpful discussion and this other set of solutions. Yay for open learning.\n\n\n# pandan::pandan_view(project = \"rethinking\", distill = TRUE, update = FALSE)\n\n\n\neasy\n2E1\n\nWhich of the expressions below correspond to the statement: the probability of rain on Monday?\n\nP(rain)\nP(rain|Monday)\nP(Monday|rain)\nP(rain, Monday) / P(Monday)\nAdapting the equation on p. 37 to a more generalised statement, for a parameter of interest \\(\\theta\\) and observations \\(y\\) dependent on that parameter, we have\n\\[\nP(\\theta | y) = \\frac{P(y|\\theta)P(\\theta)}{P(y)} = P(\\theta, y)/P(y)\n\\]\nThen P(rain|Monday) = P(rain, Monday) / P(Monday).\nSo, I conclude that 2. and 4. correspond to the statement.\n2E2\nThe following statement corresponds to the expression P(Monday|rain):\nThe probability that it is Monday, given that it is raining.\n2E3\n\nThe probability that it is Monday given that it is raining.\n\nCan be expressed\nP(Monday|rain) = P(rain|Monday)P(Monday)/P(rain)\nSo, the following statements correspond.\nP(Monday|rain) and 4. P(rain|Monday)P(Monday)/P(rain)\n2E4\n\nThe Bayesian statistician Finetti began his book on probablity theory with the declaration: “PROBABILITY DOES NOT EXIST”. What he meant is that probability is a device for describing uncertainty from the perspective ofg an observer with limited knowledge; it has no objective reality. What does it mean to say, “the probability of water is 0.7”?\n\nBased on the observations we have of water and land from globe tossing, the most credible proportion of the globe is approximately 0.7.\nmedium\n2M1\n\nCompute and plot the grid approximate posterior distribution for each of the following sets of observations. In each case, assume a uniform prior for p.\n\nWWW\nWWWL\nLWWLWWW\nWe assume \\[\n\\begin{array}\n\\\\W & \\sim & \\text{binomial}(N, p)\\\\\np & \\sim & \\text{uniform}(0, 1)\n\\end{array}\n\\] where \\(W\\) is the number of water observations and \\(N = L + W\\) is the total number of water and land observations. We only know \\(p\\) is a proportion, so we know that it falls in \\([0,1]\\).\nWe are interested in finding \\[\nP(p|W,L) = P(W,L|p)P(p)/P(W,L)\n\\] where \\(P(p|W,L)\\) is the posterior, \\(P(W,L|p)\\) is the probability of the data, \\(P(W,L)\\) is the prior.\n\nAnd this is Bayes’ theorem. It says the the probability of any particular value of \\(p\\), considering the data is equal to the product of the relative plausibility of the data, conditional on \\(p\\), and the prior plausibility of \\(p\\), divided by the average probability of the data.\n\n\\[\n\\text{Posterior} = \\frac{\n\\text{Probability of the data} \\times \\text{Prior}\n}{\n\\text{Average probability of the data}\n}\n\\]\n\n\nlibrary(tidyverse)\n\n# set number of points for the grid \nn <- 10\n\n# create a grid approximation tableT\nwww <- \n    tibble(\n        # define grid\n        p = seq(0, 1, length.out = n),\n        # compute prior at each parameter value\n        prior = 1\n    ) %>% \n    mutate(\n        # compute the likelihood at each parameter value\n        plausibility = dbinom(3, size = 3, prob = p),\n        # comput the unstandardised posterior\n        unstd_post = plausibility * prior,\n        # standardise the posterior\n        posterior = unstd_post / sum(unstd_post)\n    )\n\n\n\n\n\ngrid_plot <- function(post_df, title_text) {\npost_df %>% \n    ggplot(\n        aes(\n            x = p,\n            y = posterior\n        )\n    ) +\n    geom_line(alpha = 0.4) +\n    geom_point(alpha = 0.8) + \n    labs(title = title_text) + \n        ggthemes::theme_tufte()\n    \n}\n\n\n\nIt makes sense that for www observation, we have a monotonically increasing posterior. Higher values of \\(p\\) are more likely, given we have only observed water.\n\n\ngrid_plot(www, \"w w w\")\n\n\n\n\nNow for the second set of observations, wwwl. This should be slightly more interesting, as there is one land observation, so we know with certainty that \\(p \\neq 1\\), whereas in www, this was the most plausible value for \\(p\\).\n\n\nwwwl <- \n    tibble(\n        # define grid\n        p = seq(0, 1, length.out = n),\n        # compute prior at each parameter value\n        prior = 1\n    ) %>% \n    mutate(\n        # compute the likelihood at each parameter value\n        plausibility = dbinom(3, size = 4, prob = p),\n        # comput the unstandardised posterior\n        unstd_post = plausibility * prior,\n        # standardise the posterior\n        posterior = unstd_post / sum(unstd_post)\n    )\n\ngrid_plot(wwwl, \"w w w l\")\n\n\n\n\n\n\nlwwlwww <- \n    tibble(\n        # define grid\n        p = seq(0, 1, length.out = n),\n        # compute prior at each parameter value\n        prior = 1\n    ) %>% \n    mutate(\n        # compute the likelihood at each parameter value\n        plausibility = dbinom(5, size = 7, prob = p),\n        # comput the unstandardised posterior\n        unstd_post = plausibility * prior,\n        # standardise the posterior\n        posterior = unstd_post / sum(unstd_post)\n    )\n\ngrid_plot(lwwlwww, \"l w w l w w\")\n\n\n\n\n2M2\nWe now assume a prior \\(P: [0,1] \\to \\{0, \\theta\\}\\) such that \\[\np \\mapsto \n\\begin{cases}\n0 & p < 0.5\\\\\n\\theta & p \\geqslant 0.5\n\\end{cases}\n\\] where \\(\\theta \\in \\mathbb R^+\\), and again compute the grid approximations as in 2M1.\nNow I’ve got the general idea of each line of the grid approximation, I’ll now functionalise it.\n\n\ngrid_theta <- function(w, sample_size) {\n  # get a random positive value\n  theta <- runif(1, 1, 10000)\n  \n  # return tibble of grid approx\n     tibble(\n        # define grid\n        p = seq(0, 1, length.out = n),\n        # compute prior at each parameter value\n        prior = if_else(p < 0.5, 0, theta)\n    ) %>% \n    mutate(\n        # compute the likelihood at each parameter value\n        plausibility = dbinom(w, size = sample_size, prob = p),\n        # comput the unstandardised posterior\n        unstd_post = plausibility * prior,\n        # standardise the posterior\n        posterior = unstd_post / sum(unstd_post)\n    )\n}\n\n\n\n\n\n# www\n\ngrid_theta(3, 3) %>% \n  grid_plot(\"w w w, prior = 0 for p < 0.5\")\n\n\n\n\n\n\n# wwwl\n\ngrid_theta(3, 4) %>% \n  grid_plot(\"w w w l, prior = 0 for p < 0.5\")\n\n\n\n\n\n\n# lwwlwww\ngrid_theta(5, 7) %>% \n  grid_plot(\"l w w l w w w, prior = 0 for p < 0.5\")\n\n\n\n\nSince \\[\n\\text{Posterior} = \\frac{\n\\text{Probability of the data} \\times \\text{Prior}\n}{\n\\text{Average probability of the data}\n}\n\\] In all three questions, for \\(p< 0.5\\), the posterior is 0.\nSince the numerator is a product of the probability of the data and the prior, which is set to 0 for \\(p < 0.5\\), and any product containing zero is zero, we have a posterior of 0 for all values \\(p < 0.5\\). That is, where the prior is 0, this will always produce a posterior of 0, regardless of the value of the probability of the data.\n2M3\n\nSuppose there are two globes, one for Earth and one for Mars. The Earth globe is 70% covered in water. The Mars globe is 100% land.\n\nSo, P(water|Earth) = 0.7 and P(land|Mars) = 1.0.\n\nFurther suppose that one of these globes - you don’t know which - was tossed in the air and produced a land observation. Assume each globe was equally likely to be tossed.\n\nSo, P(Earth) = 0.5 and P(Mars) = 0.5.\n\nShow that the posterior probability that the globe was Earth conditional on seeing land is 0.23, that is, P(Earth|land) = 0.23.\n\nWe wish to show that P(Earth|land) = 0.23.\nWell, Bayes’ theorem gives us,\nP(Earth|land) = P(land|Earth)P(Earth)/P(land).\nSo we need to find P(land|Earth), P(Earth), and P(land).\nWe know P(Earth) = 0.5.\nNow P(water|Earth) = 0.7, so P(land|Earth) = 0.3, since there are only two possibilities on Earth.\nFinally, for P(land), we note that, going back to the original generalised notation, \\[\nP(y) = E(P(y|\\theta)) = \\int P(y|\\theta)P(\\theta)d\\theta\n\\] so, since in this example we are dealing with discrete possibilities,\nP(land) = E(P(land|Planet)) = \\(\\displaystyle\\sum_{\\text{Planet } \\in \\{\\text{Earth},\\text{Mars}\\}}\\) P(land|Planet)P(planet) = P(land|Earth) P(Earth) + P(land|Mars) P(Mars).\nThen P(land) is\n\n\n0.3 * 0.5 + 1 * 0.5\n\n\n[1] 0.65\n\nSo, we have P(land|Earth), by Bayes’ theorem, is\n\n\n(0.3 * 0.5)/(0.3 * 0.5 + 1 * 0.5)\n\n\n[1] 0.2307692\n\n2M4\n\nSuppose you have a deck with only three cards.\n\nLet \\(X\\) denote the set of three cards, so \\(|X|=3\\).\n\nAnd each side is either black or white. One card has two black sides. The second card has one black and one white side. The third card has two white sides.\n\nSo, we could say \\(X = \\{BB, BW, WW\\}\\).\n\nSomeone pulls out a card and places it flat on a table. A black side is shown facing up, but you don’t know the colour of the side facing down.\n\nLet \\(y\\) denote the observation \\(B\\). Now, clearly \\(P(B|WW) = 0\\).\n\nUse the counting method from Section 2. This means counting up the ways that each card could produce the observed data.\n\n\nShow that the probability that the other side is also black is 2/3.\n\nWe wish to show that \\(P(BB|B) = 2/3\\).\n\n\ntibble(\n  # possible cards\n  conjecture = c(\"BB\", \"BW\", \"WW\"),\n  # probability of each card\n  p = rep(1 / 3, 3),\n  # ways the card can produce the observation B\n  ways = c(2, 1, 0)\n) %>%\n  # calculate the plausibility\n  mutate(prod = p * ways,\n         plausibility = prod / sum(prod)) %>%\n  gt() %>%\n  cols_label(\n    conjecture = \"possible cards\",\n    p = \"likelihood of drawing card\",\n    ways = \"ways card can produce B\",\n    prod = \"p x ways\",\n    plausibility = \"plausbility - p x ways/sum(p x ways)\"\n  ) %>% \n  data_color(\n    columns = vars(plausibility),\n    colors = scales::col_bin(\n      palette = c(\"#93a1a1\", \"white\"),\n      bins = 2,\n      domain = NULL,\n      reverse = TRUE\n    )\n  ) %>% \n  data_color(\n    columns = vars(conjecture),\n    colors = scales::col_factor(\n      palette = c(\"#93a1a1\", \"white\", \"white\"),\n      domain = NULL\n    )\n  )\n\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#zxbaiafvff .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#zxbaiafvff .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#zxbaiafvff .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#zxbaiafvff .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#zxbaiafvff .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#zxbaiafvff .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#zxbaiafvff .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#zxbaiafvff .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#zxbaiafvff .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#zxbaiafvff .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#zxbaiafvff .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#zxbaiafvff .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#zxbaiafvff .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#zxbaiafvff .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#zxbaiafvff .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#zxbaiafvff .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#zxbaiafvff .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#zxbaiafvff .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#zxbaiafvff .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#zxbaiafvff .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#zxbaiafvff .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#zxbaiafvff .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#zxbaiafvff .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#zxbaiafvff .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#zxbaiafvff .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#zxbaiafvff .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#zxbaiafvff .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#zxbaiafvff .gt_left {\n  text-align: left;\n}\n\n#zxbaiafvff .gt_center {\n  text-align: center;\n}\n\n#zxbaiafvff .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#zxbaiafvff .gt_font_normal {\n  font-weight: normal;\n}\n\n#zxbaiafvff .gt_font_bold {\n  font-weight: bold;\n}\n\n#zxbaiafvff .gt_font_italic {\n  font-style: italic;\n}\n\n#zxbaiafvff .gt_super {\n  font-size: 65%;\n}\n\n#zxbaiafvff .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\npossible cards\n      likelihood of drawing card\n      ways card can produce B\n      p x ways\n      plausbility - p x ways/sum(p x ways)\n    BB\n0.3333333\n2\n0.6666667\n0.6666667BW\n0.3333333\n1\n0.3333333\n0.3333333WW\n0.3333333\n0\n0.0000000\n0.0000000\n\n2M5\nNow suppose there are four cards \\(\\{BB, BW, WW, BB\\}\\).\nAgain calculate the probability the other side is black.\nThis time I’ll use TeX so I can see how I worked it on paper.\n\\[\n\\begin{array}{cccc}\n\\text{possible card} & \\text{chance of card} & \\text{ways card produces B} & \\text{chance} \\times \\text{ways} & \\text{plausibility (product / $\\Sigma$)}\\\\\n\\hline\nBB & 1/2 & 2 & 1 & 4/5\\\\\nBW & 1/4 & 1 & 1/4 & 1/5\\\\\nWW & 1/4 & 0 & 0 & 0\\\\\n\\hline\n&&&\\Sigma = 5/4\n\\end{array}\n\\]\nSo, the probability the other side is black is\n\n\n4/5\n\n\n[1] 0.8\n\n2M6\n\nImagine the black ink is heavy, and so cards with black sides are heavier than cards with white sides.\n\nSo, P(B) < P(W).\n\nAgain assume there are three cards \\(\\{BB, BW, WW\\}\\). After experimenting a number of times, you conclude that for every way to pull the \\(BB\\) card from the bag, there are 2 ways to pull the BW card, and 3 ways to pull the WW card. Again suppose that a card is pulled and a black side appears face up. Show that the probability the other side is black is now 0.5. Use the counting method, as before.\n\n2M7\n\nAssume againt he original card problem, with a single card showing a black side face up. Before looking at the other side, we draw another card from the bag and lay it face up on the table. The face that is shown on the new card is white. Show that the probability that the first card, the one showing a black side, has black on its other side is now 0.45. Using the counting method, if you can. Hint: Treat this like the sequence of globe tosses, counting all the ways to see each observation, for each possible first card.\n\nhard\n2H1\n\nSuppose there are two species of panda bear. Both are equally common in the wild and live int he sampe places. The look exactly alide and eat the same food, and there is yet no geneetic assay capable of telling them apart. They differ however in their family sizes. Specias A gives bith to twins 10% of the time, otherwise birthing a single infant. Species B births twins 20% of the time, otherwise birhting singleton infants. Assume these numbers are known with certainty, from many years of field research.\n\n\nNow suppose you are managing a captive panda breeding program. You have a new female panda of unknown species, and she has just given birth to twins. What is the probability that her next birth will also be twins?\n\n2H2\n\nRecall all the facts from the problem above.\n\n\nNow compute the probability that the panda we have is from species A, assuming we have observed only the first birth and that it was twins.\n\n2H3\n\nContinuing on from the previous problem, suppose the same panda mother has a second birth and that it is not twins, but a singleton infant.\n\n\nCompute the posterior probability that this panda is species A.\n\n\n\n\n",
      "last_modified": "2021-07-23T10:42:47+01:00"
    },
    {
      "path": "index.html",
      "title": "measured.",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-07-25T08:38:34+01:00"
    },
    {
      "path": "README.html",
      "author": [],
      "contents": "\nonetimetrophybitch\n\n\n",
      "last_modified": "2021-07-25T08:38:34+01:00"
    },
    {
      "path": "wolfgang.html",
      "title": "Meta-analysis in R",
      "description": "Notes from Wolfgang's livestream\n",
      "author": [
        {
          "name": "Nora Jones",
          "url": "https://example.com/norajones"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\n\n\n\n                           study mdur mbase time    yi    vi \n1                 Alegret (2001) 16.1  53.6    1 -33.4  14.3 \n2                 Alegret (2001) 16.1  53.6    2    NA    NA \n3                 Alegret (2001) 16.1  53.6    3    NA    NA \n4                 Alegret (2001) 16.1  53.6    4    NA    NA \n5              Barichella (2003) 13.5  45.3    1 -20.0   7.3 \n6              Barichella (2003) 13.5  45.3    2    NA    NA \n7              Barichella (2003) 13.5  45.3    3 -30.0   5.7 \n8              Barichella (2003) 13.5  45.3    4    NA    NA \n9                  Berney (2002) 13.6  45.6    1 -21.1   7.3 \n10                 Berney (2002) 13.6  45.6    2    NA    NA \n11                 Berney (2002) 13.6  45.6    3    NA    NA \n12                 Berney (2002) 13.6  45.6    4    NA    NA \n13               Burchiel (1999) 13.6  48.0    1 -20.0   8.0 \n14               Burchiel (1999) 13.6  48.0    2 -20.0   8.0 \n15               Burchiel (1999) 13.6  48.0    3 -18.0   5.0 \n16               Burchiel (1999) 13.6  48.0    4    NA    NA \n17                   Chen (2003) 12.1  65.7    1    NA    NA \n18                   Chen (2003) 12.1  65.7    2 -32.9 125.0 \n19                   Chen (2003) 12.1  65.7    3    NA    NA \n20                   Chen (2003) 12.1  65.7    4    NA    NA \n21  DBS for PD Study Grp. (2001) 14.4  54.0    1 -25.6   4.2 \n22  DBS for PD Study Grp. (2001) 14.4  54.0    2 -28.3   4.6 \n23  DBS for PD Study Grp. (2001) 14.4  54.0    3    NA    NA \n24  DBS for PD Study Grp. (2001) 14.4  54.0    4    NA    NA \n25               Dujardin (2001) 13.1  65.0    1 -30.3  88.2 \n26               Dujardin (2001) 13.1  65.0    2    NA    NA \n27               Dujardin (2001) 13.1  65.0    3 -24.5 170.7 \n28               Dujardin (2001) 13.1  65.0    4    NA    NA \n29               Esselink (2004) 12.0  51.5    1    NA    NA \n30               Esselink (2004) 12.0  51.5    2 -25.0  17.0 \n31               Esselink (2004) 12.0  51.5    3    NA    NA \n32               Esselink (2004) 12.0  51.5    4    NA    NA \n33             Funkiewiez (2003) 14.0  56.0    1    NA    NA \n34             Funkiewiez (2003) 14.0  56.0    2    NA    NA \n35             Funkiewiez (2003) 14.0  56.0    3 -36.0   5.0 \n36             Funkiewiez (2003) 14.0  56.0    4    NA    NA \n37                 Herzog (2003) 15.0  44.9    1    NA    NA \n38                 Herzog (2003) 15.0  44.9    2 -22.5   6.8 \n39                 Herzog (2003) 15.0  44.9    3 -25.2  11.0 \n40                 Herzog (2003) 15.0  44.9    4 -25.7  15.4 \n41                 Iansek (2002) 13.0  27.6    1    NA    NA \n42                 Iansek (2002) 13.0  27.6    2  -8.6  41.0 \n43                 Iansek (2002) 13.0  27.6    3    NA    NA \n44                 Iansek (2002) 13.0  27.6    4    NA    NA \n45                   Just (2002) 14.0  44.0    1 -26.0  22.4 \n46                   Just (2002) 14.0  44.0    2 -30.0  20.6 \n47                   Just (2002) 14.0  44.0    3    NA    NA \n48                   Just (2002) 14.0  44.0    4    NA    NA \n49         Kleiner-Fisman (1999) 13.4  50.1    1    NA    NA \n50         Kleiner-Fisman (1999) 13.4  50.1    2    NA    NA \n51         Kleiner-Fisman (1999) 13.4  50.1    3 -25.5   8.2 \n52         Kleiner-Fisman (1999) 13.4  50.1    4 -19.5  13.0 \n53                  Krack (2003) 14.6  55.7    1    NA    NA \n54                  Krack (2003) 14.6  55.7    2    NA    NA \n55                  Krack (2003) 14.6  55.7    3 -36.7   5.8 \n56                  Krack (2003) 14.6  55.7    4 -32.9   6.1 \n57                 Krause (2001) 13.7  59.0    1 -27.5   3.8 \n58                 Krause (2001) 13.7  59.0    2 -23.5   3.8 \n59                 Krause (2001) 13.7  59.0    3 -29.0   3.8 \n60                 Krause (2001) 13.7  59.0    4    NA    NA \n61                 Krause (2004) 14.4  60.0    1    NA    NA \n62                 Krause (2004) 14.4  60.0    2    NA    NA \n63                 Krause (2004) 14.4  60.0    3 -25.0  13.0 \n64                 Krause (2004) 14.4  60.0    4 -23.0  15.4 \n65                  Kumar (1998) 14.3  55.7    1    NA    NA \n66                  Kumar (1998) 14.3  55.7    2 -36.3  27.3 \n67                  Kumar (1998) 14.3  55.7    3    NA    NA \n68                  Kumar (1998) 14.3  55.7    4    NA    NA \n69               Lagrange (2002) 14.0  53.7    1    NA    NA \n70               Lagrange (2002) 14.0  53.7    2    NA    NA \n71               Lagrange (2002) 14.0  53.7    3 -29.4  10.7 \n72               Lagrange (2002) 14.0  53.7    4    NA    NA \n73               Limousin (1998) 14.0  57.0    1 -31.0   2.6 \n74               Limousin (1998) 14.0  57.0    2 -34.0   2.0 \n75               Limousin (1998) 14.0  57.0    3 -32.5   2.0 \n76               Limousin (1998) 14.0  57.0    4    NA    NA \n77             Linazasoro (2003) 13.7  47.7    1    NA    NA \n78             Linazasoro (2003) 13.7  47.7    2    NA    NA \n79             Linazasoro (2003) 13.7  47.7    3 -20.6  25.3 \n80             Linazasoro (2003) 13.7  47.7    4    NA    NA \n81                Lopiano (2001) 15.4  59.8    1 -33.9  20.1 \n82                Lopiano (2001) 15.4  59.8    2    NA    NA \n83                Lopiano (2001) 15.4  59.8    3    NA    NA \n84                Lopiano (2001) 15.4  59.8    4    NA    NA \n85                  Macia (2004) 15.0  55.2    1    NA    NA \n86                  Macia (2004) 15.0  55.2    2    NA    NA \n87                  Macia (2004) 15.0  55.2    3 -35.4  21.2 \n88                  Macia (2004) 15.0  55.2    4    NA    NA \n89        Martinez-Martin (2002) 16.4  55.7    1    NA    NA \n90        Martinez-Martin (2002) 16.4  55.7    2 -34.9  18.0 \n91        Martinez-Martin (2002) 16.4  55.7    3    NA    NA \n92        Martinez-Martin (2002) 16.4  55.7    4    NA    NA \n93              Molinuevo (2000) 15.8  49.6    1    NA    NA \n94              Molinuevo (2000) 15.8  49.6    2 -32.7  16.3 \n95              Molinuevo (2000) 15.8  49.6    3    NA    NA \n96              Molinuevo (2000) 15.8  49.6    4    NA    NA \n97                   Moro (1999) 15.4  67.6    1 -23.0  38.1 \n98                   Moro (1999) 15.4  67.6    2 -24.1  32.9 \n99                   Moro (1999) 15.4  67.6    3 -27.8  31.0 \n100                  Moro (1999) 15.4  67.6    4 -28.3  34.6 \n101            Ostergaard (2002) 15.0  51.3    1 -31.2  12.7 \n102            Ostergaard (2002) 15.0  51.3    2    NA    NA \n103            Ostergaard (2002) 15.0  51.3    3 -33.0   9.5 \n104            Ostergaard (2002) 15.0  51.3    4    NA    NA \n105                 Pahwa (2003) 12.1  41.3    1 -16.2   5.9 \n106                 Pahwa (2003) 12.1  41.3    2    NA    NA \n107                 Pahwa (2003) 12.1  41.3    3 -16.3   7.0 \n108                 Pahwa (2003) 12.1  41.3    4 -11.5  12.7 \n109                 Patel (2003) 10.0  47.8    1    NA    NA \n110                 Patel (2003) 10.0  47.8    2    NA    NA \n111                 Patel (2003) 10.0  47.8    3 -29.2   5.8 \n112                 Patel (2003) 10.0  47.8    4    NA    NA \n113               Perozzo (2001) 15.4  59.7    1    NA    NA \n114               Perozzo (2001) 15.4  59.7    2 -31.7  12.4 \n115               Perozzo (2001) 15.4  59.7    3    NA    NA \n116               Perozzo (2001) 15.4  59.7    4    NA    NA \n117      Pinter (1999) - Long FU 11.3  60.0    1 -32.2  26.5 \n118      Pinter (1999) - Long FU 11.3  60.0    2    NA    NA \n119      Pinter (1999) - Long FU 11.3  60.0    3 -32.9  29.0 \n120      Pinter (1999) - Long FU 11.3  60.0    4    NA    NA \n121     Pinter (1999) - Short FU 11.5  59.7    1 -31.7  19.1 \n122     Pinter (1999) - Short FU 11.5  59.7    2    NA    NA \n123     Pinter (1999) - Short FU 11.5  59.7    3    NA    NA \n124     Pinter (1999) - Short FU 11.5  59.7    4    NA    NA \n125        Rodriguez-Oroz (2000) 16.5  51.5    1 -29.3  22.9 \n126        Rodriguez-Oroz (2000) 16.5  51.5    2 -32.0  20.0 \n127        Rodriguez-Oroz (2000) 16.5  51.5    3 -36.7  17.8 \n128        Rodriguez-Oroz (2000) 16.5  51.5    4    NA    NA \n129                Romito (2003) 13.8  63.9    1 -30.1   9.4 \n130                Romito (2003) 13.8  63.9    2 -30.5   8.7 \n131                Romito (2003) 13.8  63.9    3 -29.7  10.4 \n132                Romito (2003) 13.8  63.9    4 -31.9  13.3 \n133             Rousseaux (2004) 12.0  52.3    1 -17.6  28.4 \n134             Rousseaux (2004) 12.0  52.3    2    NA    NA \n135             Rousseaux (2004) 12.0  52.3    3    NA    NA \n136             Rousseaux (2004) 12.0  52.3    4    NA    NA \n137         Russman (2004) (21m) 15.9  47.1    1    NA    NA \n138         Russman (2004) (21m) 15.9  47.1    2    NA    NA \n139         Russman (2004) (21m) 15.9  47.1    3    NA    NA \n140         Russman (2004) (21m) 15.9  47.1    4 -22.9  20.0 \n141             Schneider (2003) 17.0  51.3    1    NA    NA \n142             Schneider (2003) 17.0  51.3    2    NA    NA \n143             Schneider (2003) 17.0  51.3    3 -36.0  27.7 \n144             Schneider (2003) 17.0  51.3    4    NA    NA \n145          Seif (2004) (17.5m) 15.0  44.2    1    NA    NA \n146          Seif (2004) (17.5m) 15.0  44.2    2    NA    NA \n147          Seif (2004) (17.5m) 15.0  44.2    3    NA    NA \n148          Seif (2004) (17.5m) 15.0  44.2    4 -22.5  20.3 \n149                Simuni (2002) 16.7  43.5    1 -19.4   1.6 \n150                Simuni (2002) 16.7  43.5    2 -18.0   1.7 \n151                Simuni (2002) 16.7  43.5    3 -20.5   1.5 \n152                Simuni (2002) 16.7  43.5    4    NA    NA \n153       Straits-Troster (2000)  8.0  47.4    1  -9.3  85.2 \n154       Straits-Troster (2000)  8.0  47.4    2    NA    NA \n155       Straits-Troster (2000)  8.0  47.4    3    NA    NA \n156       Straits-Troster (2000)  8.0  47.4    4    NA    NA \n157               Thobois (2002) 13.5  44.9    1    NA    NA \n158               Thobois (2002) 13.5  44.9    2 -24.7  15.5 \n159               Thobois (2002) 13.5  44.9    3 -27.9  17.1 \n160               Thobois (2002) 13.5  44.9    4    NA    NA \n161               Troster (2003)  9.5  41.6    1 -16.7   9.8 \n162               Troster (2003)  9.5  41.6    2    NA    NA \n163               Troster (2003)  9.5  41.6    3    NA    NA \n164               Troster (2003)  9.5  41.6    4    NA    NA \n165          Valldeoriola (2002) 15.6  49.0    1    NA    NA \n166          Valldeoriola (2002) 15.6  49.0    2 -31.2 196.0 \n [ reached 'max' / getOption(\"max.print\") -- omitted 18 rows ] \n                          study mdur mbase time    yi    vi \n1                Alegret (2001) 16.1  53.6    1 -33.4  14.3 \n2             Barichella (2003) 13.5  45.3    1 -20.0   7.3 \n3             Barichella (2003) 13.5  45.3    3 -30.0   5.7 \n4                 Berney (2002) 13.6  45.6    1 -21.1   7.3 \n5               Burchiel (1999) 13.6  48.0    1 -20.0   8.0 \n6               Burchiel (1999) 13.6  48.0    2 -20.0   8.0 \n7               Burchiel (1999) 13.6  48.0    3 -18.0   5.0 \n8                   Chen (2003) 12.1  65.7    2 -32.9 125.0 \n9  DBS for PD Study Grp. (2001) 14.4  54.0    1 -25.6   4.2 \n10 DBS for PD Study Grp. (2001) 14.4  54.0    2 -28.3   4.6 \n\n\n      [,1]     [,2]     [,3] [,4]     [,5]     [,6]     [,7] [,8]\n [1,] 14.3 0.000000 0.000000  0.0 0.000000 0.000000 0.000000    0\n [2,]  0.0 7.300000 6.069352  0.0 0.000000 0.000000 0.000000    0\n [3,]  0.0 6.069352 5.700000  0.0 0.000000 0.000000 0.000000    0\n [4,]  0.0 0.000000 0.000000  7.3 0.000000 0.000000 0.000000    0\n [5,]  0.0 0.000000 0.000000  0.0 8.000000 7.760000 5.950774    0\n [6,]  0.0 0.000000 0.000000  0.0 7.760000 8.000000 6.134819    0\n [7,]  0.0 0.000000 0.000000  0.0 5.950774 6.134819 5.000000    0\n [8,]  0.0 0.000000 0.000000  0.0 0.000000 0.000000 0.000000  125\n [9,]  0.0 0.000000 0.000000  0.0 0.000000 0.000000 0.000000    0\n[10,]  0.0 0.000000 0.000000  0.0 0.000000 0.000000 0.000000    0\n          [,9]    [,10]\n [1,] 0.000000 0.000000\n [2,] 0.000000 0.000000\n [3,] 0.000000 0.000000\n [4,] 0.000000 0.000000\n [5,] 0.000000 0.000000\n [6,] 0.000000 0.000000\n [7,] 0.000000 0.000000\n [8,] 0.000000 0.000000\n [9,] 4.200000 4.263589\n[10,] 4.263589 4.600000\n\n\n\nMultivariate Meta-Analysis Model (k = 82; method: REML)\n\nVariance Components:\n\nouter factor: study (nlvls = 46)\ninner factor: time  (nlvls = 4)\n\n           estim  sqrt  k.lvl  fixed  level \ntau^2.1    22.73  4.77     24     no      1 \ntau^2.2    33.73  5.81     22     no      2 \ntau^2.3    26.14  5.11     25     no      3 \ntau^2.4    31.18  5.58     11     no      4 \nrho         0.88                  no        \n\nTest for Residual Heterogeneity:\nQE(df = 78) = 856.16, p-val < .01\n\nTest of Moderators (coefficients 1:4):\nQM(df = 4) = 873.16, p-val < .01\n\nModel Results:\n\n               estimate    se    zval  pval   ci.lb   ci.ub \nfactor(time)1    -25.90  1.01  -25.60  <.01  -27.89  -23.92  *** \nfactor(time)2    -27.46  1.14  -24.08  <.01  -29.70  -25.23  *** \nfactor(time)3    -28.66  1.03  -27.76  <.01  -30.68  -26.63  *** \nfactor(time)4    -26.49  1.38  -19.17  <.01  -29.20  -23.79  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n",
      "last_modified": "2021-07-23T10:35:12+01:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
